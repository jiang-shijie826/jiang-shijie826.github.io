{"meta":{"title":"冰凉西瓜の博客","subtitle":"","description":"","author":"John Doe","url":"https://jiang-shijie826.github.io","root":"/"},"pages":[{"title":"404 Not Found：该页无法显示","date":"2023-02-23T03:08:37.162Z","updated":"2023-02-15T13:18:57.528Z","comments":false,"path":"/404.html","permalink":"https://jiang-shijie826.github.io/404.html","excerpt":"","text":""},{"title":"关于","date":"2023-02-23T03:08:37.163Z","updated":"2023-02-15T13:18:57.528Z","comments":false,"path":"about/index.html","permalink":"https://jiang-shijie826.github.io/about/index.html","excerpt":"","text":"个人详细介绍"},{"title":"分类","date":"2023-03-02T06:09:45.645Z","updated":"2023-02-15T13:18:57.529Z","comments":false,"path":"categories/index.html","permalink":"https://jiang-shijie826.github.io/categories/index.html","excerpt":"","text":""},{"title":"书单","date":"2023-02-23T03:08:37.164Z","updated":"2023-02-15T13:18:57.529Z","comments":false,"path":"books/index.html","permalink":"https://jiang-shijie826.github.io/books/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2023-05-26T05:49:55.131Z","updated":"2023-02-15T13:18:57.529Z","comments":true,"path":"links/index.html","permalink":"https://jiang-shijie826.github.io/links/index.html","excerpt":"","text":""},{"title":"仓库","date":"2023-03-02T07:32:50.517Z","updated":"2023-03-02T07:32:50.517Z","comments":false,"path":"repository/index.html","permalink":"https://jiang-shijie826.github.io/repository/index.html","excerpt":"","text":""},{"title":"标签","date":"2023-03-02T07:32:42.842Z","updated":"2023-02-15T13:18:57.529Z","comments":false,"path":"tags/index.html","permalink":"https://jiang-shijie826.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"利用spark同步Hbase数据到ElasticSearch","slug":"利用spark同步Hbase数据到ElasticSearch","date":"2025-03-21T01:52:17.000Z","updated":"2025-03-21T02:12:49.536Z","comments":true,"path":"2025/03/21/利用spark同步Hbase数据到ElasticSearch/","permalink":"https://jiang-shijie826.github.io/2025/03/21/%E5%88%A9%E7%94%A8spark%E5%90%8C%E6%AD%A5Hbase%E6%95%B0%E6%8D%AE%E5%88%B0ElasticSearch/","excerpt":"","text":"利用spark同步Hbase数据到ElasticSearch 主要实现思路:利用spark-submit 命令 + Scala 代码(亲测:同步10万条数据,38s左右) 具体实现步骤如下: 1.安装hadoop、habse、zooker、sacla、spark参考此篇博客进行搭建: [https://blog.csdn.net/qq_51235856/article/details/125712898]: 2.编写同步jar包(利用scala语言，编写项目，打包成jar，上传到服务器) Idea中安装Scala插件 新建Scala项目 在build.sbt中引入依赖,导入的依赖需要考虑兼容性 12345678910111213141516171819ThisBuild / version := &quot;v1&quot;ThisBuild / scalaVersion := &quot;2.11.12&quot;lazy val root = (project in file(&quot;.&quot;)) .settings( name := &quot;spark2es&quot;, idePackagePrefix := Some(&quot;com.xxxx.xxxx&quot;) )libraryDependencies += &quot;org.apache.spark&quot; %% &quot;spark-core&quot; % &quot;2.4.0&quot;libraryDependencies += &quot;org.elasticsearch&quot; %% &quot;elasticsearch-spark-20&quot; % &quot;7.17.25&quot;libraryDependencies += &quot;org.apache.hbase&quot; % &quot;hbase-client&quot; % &quot;2.5.6&quot;libraryDependencies += &quot;org.apache.hbase&quot; % &quot;hbase-server&quot; % &quot;2.5.6&quot;libraryDependencies += &quot;org.apache.hbase.connectors.spark&quot; % &quot;hbase-spark&quot; % &quot;1.0.0&quot;libraryDependencies += &quot;org.apache.spark&quot; %% &quot;spark-sql&quot; % &quot;2.4.0&quot;libraryDependencies += &quot;com.alibaba&quot; % &quot;fastjson&quot; % &quot;1.2.77&quot;libraryDependencies += &quot;org.apache.hbase&quot; % &quot;hbase-mapreduce&quot; % &quot;2.5.6&quot;libraryDependencies += &quot;org.scala-lang&quot; % &quot;scala-library&quot; % &quot;2.11.12&quot; 新建scala文件 编写文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144object HBaseToElasticsearchMultipleTables &#123; private final val logger: Logger = Logger.getLogger(HBaseToElasticsearchMultipleTables.getClass) logger.setLevel(Level.DEBUG) //定义Hbase中需要同步的表 private val parserMapping: Map[String, Result =&gt; Map[String, String]] = Map( &quot;student&quot; -&gt; parsestudent, ....更多数据 ) // 定义多个表和对应的索引 private final val tablesAndIndexes = Seq( //student:Hbase表名 student:es索引名 atsn:列簇 (&quot;student&quot;, &quot;student&quot;, &quot;atsn&quot;), ....更多数据 ) //student def parsestudent(result: Result): Map[String, String] = &#123; //Hbase中的rowkey val rowKey = Bytes.toString(result.getRow) val userId = Bytes.toString(result.getValue(Bytes.toBytes(&quot;atsn&quot;), Bytes.toBytes(&quot;userId&quot;))) ....更多数据 // 构建 Elasticsearch 文档 Map( //key:Es中的字段名 rowKey:Hbase的列名 &quot;key&quot; -&gt; rowKey, &quot;userId&quot; -&gt; userId, ....更多数据 ) &#125; def main(args: Array[String]): Unit = &#123; // 创建 SparkSession val spark = SparkSession.builder() .appName(&quot;HBaseToElasticsearch&quot;) //true:连接器将禁用节点发现功能 .config(&quot;spark.es.nodes.wan.only&quot;, &quot;true&quot;) //指定es中id为Hbase中的rowkey,也可以由es自动生成 .config(&quot;spark.es.mapping.id&quot;, &quot;key&quot;) // upsert操作 .config(&quot;spark.es.write.operation&quot;, &quot;upsert&quot;) // 自动创建索引 .config(&quot;spark.es.index.auto.create&quot;, &quot;true&quot;) .getOrCreate() logger.info(&quot;Elasticsearch init Success~~~&quot;) val startTime = System.currentTimeMillis() // HBase 配置 val hbaseConf = HBaseConfiguration.create() // 统计同步的总条数 var totalCount = 0L; var metricsList = List.empty[Map[String, Any]] //循环遍历表和索引 tablesAndIndexes.foreach &#123; case (hbaseTable, esIndex, family) =&gt; hbaseConf.set(TableInputFormat.INPUT_TABLE, hbaseTable) // HBase 表名 // 定义 Scan val scan = new Scan() scan.addFamily(Bytes.toBytes(family)) // 列族名 val scanStr = Base64.getEncoder.encodeToString(ProtobufUtil.toScan(scan).toByteArray) hbaseConf.set(TableInputFormat.SCAN, scanStr) // 读取 HBase 数据 val hbaseRDD = spark.sparkContext.newAPIHadoopRDD( hbaseConf, classOf[TableInputFormat], classOf[ImmutableBytesWritable], classOf[Result] ) // 处理数据并转换为 Elasticsearch 格式 val parseFunction = parserMapping.getOrElse(hbaseTable, throw new IllegalArgumentException(s&quot;未注册的表解析器: $hbaseTable&quot;)) //增加 Spark 作业的并行度,提高写入性能 val targetPartitions = spark.sparkContext.defaultParallelism * 4 logger.info(s&quot;hbaseRDD.repartition $&#123;targetPartitions&#125;&quot;) //映射Hbase中的列名和Es中的字段名 val esRDD = hbaseRDD.repartition(targetPartitions).mapPartitions &#123; partition =&gt; partition.flatMap &#123; case (_, result) =&gt; try &#123; if (result != null) Some(parseFunction(result)) else None &#125; catch &#123; case e: Exception =&gt; // 建议在此添加异常日志记录逻辑 logger.info(s&quot;Error processing result: $&#123;e.getMessage&#125;&quot;) None &#125; &#125; &#125;.persist(StorageLevel.MEMORY_ONLY_SER) try &#123; // 将数据写入 Elasticsearch esRDD.saveToEs(s&quot;$esIndex/_doc&quot;, Map(&quot;es.mapping.id&quot; -&gt; &quot;key&quot;)) logger.info(s&quot;Elasticsearch Index $&#123;esIndex&#125; sync success~~~&quot;) // 将该索引的统计指标封装成 Map val count = esRDD.count() totalCount += count val metric = Map(&quot;hbaseTable&quot; -&gt; hbaseTable, &quot;count&quot; -&gt; count) metricsList = metric :: metricsList &#125; catch &#123; case e: Exception =&gt; &#123; logger.error(&quot;插入es错误!&quot; + e.getMessage) e.printStackTrace() &#125; &#125; finally &#123; esRDD.unpersist() &#125; &#125; val endTime = System.currentTimeMillis() val btTime = endTime - startTime logger.info(&quot;Sync Time:&quot; + btTime + &quot;ms~~~&quot;) // 将总体执行时间等信息封装成 Map 对象 val jobName = &quot;HBaseToESSync_&quot; + String.valueOf(System.currentTimeMillis()); val sdf = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;) val metrics = Map( &quot;jobName&quot; -&gt; jobName, &quot;totalCount&quot; -&gt; totalCount, &quot;jobDetail&quot; -&gt; metricsList, &quot;startTime&quot; -&gt; sdf.format(new Date(startTime)), &quot;endTime&quot; -&gt; sdf.format(new Date(endTime)), &quot;executionTime_ms&quot; -&gt; btTime, &quot;timestamp&quot; -&gt; System.currentTimeMillis() ) // 将指标写入到 ES 中的另一个索引（例如 job_metrics） spark.sparkContext.parallelize(Seq(metrics)) .saveToEs(&quot;job_metrics/_doc&quot;, Map(&quot;es.mapping.id&quot; -&gt; &quot;jobName&quot;)) spark.stop() &#125;&#125; 打包文件 clean package 3.编写spark执行脚本123456789101112131415161718#!/bin/bashfilename=/root/spark-2.4.0-bin/dist/$(date +%Y)/$(date +%m)/$(date +%d)if [ ! -d &quot;$filename&quot; ]; then mkdir -p &quot;$filename&quot;fi/root/spark-2.4.0-bin/bin/spark-submit \\ --class com.xxxx.xxxx.HBaseToElasticsearchMultipleTables \\ --master local[*] \\ --packages org.scala-lang:scala-library:2.11.12,org.apache.hbase:hbase-client:2.5.6,org.apache.hbase:hbase-mapreduce:2.5.6,org.elasticsearch:elasticsearch-spark-20_2.11:7.17.25 \\ --conf spark.es.nodes=&quot;xx.xx.xx.xx:9200&quot; \\ //Elasticsearch 节点的地址 --conf spark.es.batch.size.bytes=&quot;10mb&quot; \\ //控制写入 Elasticsearch 时的批处理大小 --conf spark.es.batch.size.entries=&quot;5000&quot; \\ //控制写入 Elasticsearch 时的批处理大小 --conf spark.es.batch.write.refresh=&quot;false&quot; \\ //设置为 false，以减少写入时的刷新频率，提高性能 --conf spark.hbase.zookeeper.quorum=&quot;hbase1&quot; \\ //配置 HBase 集群信息 --conf spark.hbase.zookeeper.property.clientPort=&quot;2181&quot; \\ //配置 HBase 的 Zookeeper 集群信息 --conf spark.serializer=&quot;org.apache.spark.serializer.KryoSerializer&quot; \\ //指定使用 Kryo 序列化器，以提高序列化性能 /root/spark-2.4.0-bin/dist/spark2es_2.11-v1.jar &gt;&gt; $filename/$(date +%Y%m%d)_sync.log 2&gt;&amp;1 &amp; //指定包含主类的可执行 JAR 文件,将输出日志重定向到指定文件，并在后台运行该命令 class:Jar包执行的主类 packages:spark执行需要加载的依赖 conf:spark连接的配置项,在这配置增加了灵活性,也可以在代码中配置 &#x2F;root&#x2F;spark-2.4.0-bin&#x2F;dist&#x2F;spark2es_2.11-v1.jar:指定jar路劲,输出执行日志 4.服务器设置定时任务crontab执行crontab -e 110 07 * * * /root/spark-2.4.0-bin/dist/run_sync.sh 5.同步阿里云hbase数据，需要添加认证参数1234567kinit -kt /path/to/your.keytab your_user@YOUR-REALM.COM#####添加 Kerberos 认证和 HBase 相关配置--conf spark.driver.extraJavaOptions=&quot;-Djava.security.krb5.conf=/etc/krb5.conf&quot; \\--conf spark.executor.extraJavaOptions=&quot;-Djava.security.krb5.conf=/etc/krb5.conf&quot; \\--conf spark.hadoop.hbase.security.authentication=&quot;kerberos&quot; \\--conf spark.hadoop.hbase.master.kerberos.principal=&quot;hbase/_HOST@YOUR-REALM.COM&quot; \\--conf spark.hadoop.hbase.regionserver.kerberos.principal=&quot;hbase/_HOST@YOUR-REALM.COM&quot; \\ 6.在 spark-submit 中用 –files 传递 hbase-site.xml12345--files /etc/hbase/conf/hbase-site.xml \\--conf spark.executor.extraClassPath=./hbase-site.xml \\--conf spark.driver.extraClassPath=./hbase-site.xml \\#并在代码中加载它hBaseConf.addResource(&quot;hbase-site.xml&quot;) 7.ElasticSearch可以看到有定时任务的索引生成,可以看到执行的时间以及同步的数据量大小","categories":[{"name":"技术","slug":"技术","permalink":"https://jiang-shijie826.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://jiang-shijie826.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"}]},{"title":"MySQL","slug":"MySQL","date":"2023-07-28T01:21:15.000Z","updated":"2025-03-21T02:29:01.741Z","comments":true,"path":"2023/07/28/MySQL/","permalink":"https://jiang-shijie826.github.io/2023/07/28/MySQL/","excerpt":"","text":"附录: DQL(Dimensional Query Language):数据查询语言DQL基本结构是由SELECT子句，FROM子句，WHERE子句组成的查询块：SELECT &lt;字段名表&gt;FROM &lt;表或视图名&gt;WHERE &lt;查询条件&gt; DML(data manipulation language)：DML用来对数据库里的数据进行操作的语言,例如UPDATE、INSERT、DELETE DDL(data definition language)： DDL主要是用在定义或改变表（TABLE）的结构，数据类型，表之间的链接和约束等初始化工作上，他们大多在建立表时使用,主要的命令有CREATE、ALTER、DROP、TRUNCATE等 DCL(Data Control Language)：DCL是数据库控制功能。是用来设置或更改数据库用户或角色权限的语句，包括（grant,deny,revoke等）语句。在默认状态下，只有sysadmin,dbcreator,db_owner或db_securityadmin等人员才有权力执行DCL 1. Innodb存储引擎1.1架构MySQL5.5版本开始，默认使用InnoDB存储引擎，它擅长事务处理，具有崩溃恢复特性，在日常开发中使用广泛。下图是InnoDB架构图，左侧为内存结构，右侧为磁盘结构。 内存结构 ​ ①Buffer pool：在执行增删改查操作时，先操作缓冲池中的数据，(缓冲池没有数据，再去磁盘加载并缓存在缓冲池中)，然后再以一定 ​ 的频率刷新到磁盘中，减少磁盘IO，加快处理速度。 ​ 缓冲池以page为单位，底层采用链表数据结构管理page。 ​ ②change buffer：更改缓冲区（针对非唯一的二级索引页）。在执行DML语句时，如果数据不存在于Buffer pool，就把数据从磁盘加载 ​ 到更改缓冲区，在更改缓冲区完成操作后，以一定的频率刷新到Buffer pool，再由Buffer pool刷新到磁盘。二级索引的DML操作是主键 ​ 乱序插入的，频繁乱序的磁盘IO会大大减低处理速度，这就是change buffer存在的意义。 ​ ③Adaptive Hash Index：自适应hash索引，用于优化buffer pool数据的查询。 ​ ④log buffer：日志缓冲区。用来保存要写入磁盘的log日志（redo log、undo log），默认为16M，日志缓冲区的日志会定期刷新到磁 ​ 盘。可以通过增加日志缓冲区的大小来减少磁盘IO。 ​ 参数： ​ innodb_log_buffer_size：缓冲区大小 ​ innodb_flush_log_at_trx_commit：刷新日志时机（0：每次事务提交时刷新到磁盘；1：每秒刷新到磁盘；2：日志在每次事务提交后 写入，并每秒刷新到磁盘）。 磁盘结构 ​ ①system tablespace：系统表空间是更改缓冲区的存储区域。 ​ ②file-per-table tablespace：每个表的文件表空间。每一张表都会生成一个独立的表空间文件。 ​ ③general tablespaces：通用表空间，默认不存在，但可以手动创建，手动指定关联。 ​ ④doublewrite buffer files:双写缓冲区。InnoDB引擎将数据页从buffer pool刷新到磁盘前，先将数据页写入双写缓冲区文件中，便于系 ​ 统异常时恢复数据。 ​ ⑤undo tablespace：撤销表空间，MySQL实例在初始化时会自动创建两个默认的undo表空间（大小默认16M），用于存储undo log。 ​ ⑥temporary tablespaces：临时表空间，用于存放临时表等数据。 ​ ⑦redo log：重做日志，用来实现事务的持久性。当事务提交之后，会把所有修改信息都存到该日志中，用于在刷新脏页到磁盘发生错 ​ 误时，进行数据恢复使用。 1.2 事务原理 redo log ​ 重做日志，记录的是事务提交时数据页的物理修改，是用来实现事务的持久性。 undo log ​ 回滚日志,用于记录数据被修改前的信息,作用包含两个:提供回滚和MVCC(多版本并发控制) 原子性：undo log 持久性：redo log 一致性：undo log +redo log 隔离性：锁+MVCC 1.3 MVCC2.B+树索引是一种数据结构，用于帮助我们在大量数据中快速定位到我们想要查找的数据。 索引在mysql数据库中分三类： B+树索引 Hash索引 全文索引 根据上图我们来看下B+树和B树有什么不同。 B+树非叶子节点上是不存储数据的，仅存储键值，而B树节点中不仅存储键值，也会存储数据。之所以这么做是因为在数据库中页的大小是固定的，innodb中页的默认大小是16KB。如果不存储数据，那么就会存储更多的键值，相应的树的阶数（节点的子节点树）就会更大，树就会更矮更胖，如此一来我们查找数据进行磁盘的IO次数有会再次减少，数据查询的效率也会更快。另外，B+树的阶数是等于键值的数量的，如果我们的B+树一个节点可以存储1000个键值，那么3层B+树可以存储1000×1000×1000&#x3D;10亿个数据。一般根节点是常驻内存的，所以一般我们查找10亿数据，只需要2次磁盘IO。 因为B+树索引的所有数据均存储在叶子节点，而且数据是按照顺序排列的。那么B+树使得范围查找，排序查找，分组查找以及去重查找变得异常简单。而B树因为数据分散在各个节点，要实现这一点是很不容易的。 有心的读者可能还发现上图B+树中各个页之间是通过双向链表连接的，叶子节点中的数据是通过单向链表连接的。 其实上面的B树我们也可以对各个节点加上链表。其实这些不是它们之前的区别，是因为在mysql的innodb存储引擎中，索引就是这样存储的。也就是说上图中的B+树索引就是innodb中B+树索引真正的实现方式，准确的说应该是聚集索引（聚集索引和非聚集索引下面会讲到）。 通过上图可以看到，在innodb中，我们通过数据页之间通过双向链表连接以及叶子节点中数据之间通过单向链表连接的方式可以找到表中所有的数据。 MyISAM中的B+树索引实现与innodb中的略有不同。在MyISAM中，B+树索引的叶子节点并不存储数据，而是存储数据的文件地址。 3.优化案例 mysql嵌套子查询效率确实比较低， 可以将其优化成连接查询 学会分析sql执行计划，mysql会对sql进行优化，所以分析执行计划很重要 内连接查询的时候，不管谁是左表右表，执行结果都一样。因为mysql会自动把小结果集的表选为驱动表（ 驱动表无论如何都会被全表扫描 ），大结果集的表选为被驱动表，被驱动表上的索引才生效。所以一般都是先执行where过滤，用到大表中的索引，然后再把小表和过滤后的大表关联到一起 简单来说就是小表驱动大表，大表索引过滤 4.乐观锁悲观锁 **悲观锁：**又称排他锁，具有很强的排他性，在数据处理过程中会将数据出于锁定状态。 悲观锁的实现往往是依靠数据库提供的锁机制。 关系数据库锁机制有： 行级锁，标级锁，读锁，写锁，都是在操作之前先上锁。 悲观锁的隔离级别可以看做可重复读。 乐观锁: 相对悲观锁而言，乐观锁机制采取了更加宽松的加锁机制，大多是基于版本号（ Version ）记录机制实现，而不需要借助数据库的锁机制。乐观锁的本质不是锁，其隔离级别可以看作为读未提交 悲观锁的优缺点： 悲观锁的优点是能避免冲突的发生。 悲观锁的缺点是开销较大，而且加锁时间较长，对于并发的访问性支持不好。 乐观锁的优缺点： 乐观锁的优点是避免了长事务中的数据库加锁解锁开销，大大提升了大并发量下的系统整体性能表现。 乐观锁的缺点是只能在提交数据时才发现业务事务将要失败，如果系统的冲突非常的多，而且一旦冲突就要因为重新计算提交而造成较大的代价的话，乐观锁也会带来很大的问题。 乐观锁与悲观锁的选择： 乐观锁适用多读场景。 悲观锁适用于多写的场景，避免了产生冲突。 5.日志MySQL三大日志包括：undolog，redo log，binlog，它们分别有以下作用： undolog：是Innodb存储引擎生成的日志。用于事务的回滚和MVCC，保证了事务的原子性。 redo log：是Innodb存储引擎生成的日志。用于崩溃后修复数据，保证了事务的持久性。 binlog：是Server层生成的日志。用于备份数据，集群等。 MySQL三大日志_#HashMap#的博客-CSDN博客 6.主从同步7.集群","categories":[{"name":"数据库","slug":"数据库","permalink":"https://jiang-shijie826.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://jiang-shijie826.github.io/tags/MySQL/"}]},{"title":"Redis","slug":"Redis","date":"2023-07-27T09:34:37.000Z","updated":"2023-07-27T09:36:13.803Z","comments":true,"path":"2023/07/27/Redis/","permalink":"https://jiang-shijie826.github.io/2023/07/27/Redis/","excerpt":"","text":"1.使用案例 计数器 限速器 使用 bitmap 实现用户上线次数统计 String类型的使用场景 计数器 统计多单位的数量:uuid:123444:follow 0 粉丝数 对象存储缓存 List类型的使用场景 消息排队 消息队列 栈 Hash类型的使用场景 Hash变更的数据 user name age,尤其是用户信息之类的,经常变动的信息! Hash更适合对象的存储,String更适合字符串存储! Set类型的使用场景 交集、并集、差集等场景的使用 ZSet类型的使用场景 set排序,存储班级成绩表 工资表排序 普通消息,1.重要消息 2.带权重进行判断 排行榜应用实现,取Top N测试 Geospatial(地理位置) 通过georadius就可以完成附近的人功能 withcoord:带上坐标 withdist:带上距离,单位与半径单位相同 COUNT n:只显示前n个(按距离递增排序) Hyperloglog(基数统计) 网页的访问量 2.线程模型(132条消息) Redis源码剖析——线程模型_redis线程模型_oywLearning的博客-CSDN博客 3.哨兵模式在 Redis 主从复制模式中，因为系统不具备自动恢复的功能，所以当主服务器（master）宕机后，需要手动把一台从服务器（slave）切换为主服务器。在这个过程中，不仅需要人为干预，而且还会造成一段时间内服务器处于不可用状态，同时数据安全性也得不到保障，因此主从模式的可用性较低，不适用于线上生产环境。 Redis 官方推荐一种高可用方案，也就是 Redis Sentinel 哨兵模式，它弥补了主从模式的不足。Sentinel 通过监控的方式获取主机的工作状态是否正常，当主机发生故障时， Sentinel 会自动进行 Failover（即故障转移），并将其监控的从机提升主服务器（master），从而保证了系统的高可用性。 Redis集群：Sentinel哨兵模式（详细图解） (biancheng.net) 4.集群(132条消息) Redis集群（Cluster）_Hpuers的博客-CSDN博客 5.缓存击穿\\缓存穿透\\缓存雪崩解决方案[(132条消息) Redis]缓存穿透、缓存击穿、缓存雪崩问题及解决方法_Bruce1801的博客-CSDN博客 6.JedisJedis就是集成了redis的一些命令操作，封装了redis的java客户端。并且提供了连接池管理。 (132条消息) Redis之jedis_redis jedis_yzm4399的博客-CSDN博客 7.Redission(132条消息) 专题四 Redis分布式锁中——Redission_v_BinWei_v的博客-CSDN博客 8.MongoDB使用案例MongoDB的适用场景 网站数据：MongoDB非常适合实时插入，更新与查询，并具备网站实时数据存储所需的复制及高度伸缩性。 缓存：由于性能很高，Mongo也适合作为信息存储的缓存层。在系统重启之后，由Mongo搭建的持久化缓存层可以避免下层数据资源过载。 大尺寸、低价值的数据：使用传统的关系型数据库存储一些大尺寸低价值数据时比较浪费资源，在此之前，很多程序员往往选择使用传统文件存储的方式。 高伸缩性的场景：Mongo非常适合由数十台或数百台服务器组成的数据库，Mongo的线路图中已经包含对MapReduce引擎的内置支持以及集群高可用的解决方案。 用于对象及JSON数据的存储：Mongo的BSON数据格式非常适合文档化的存储及查询。MongoDB的行业应用场景 游戏场景：使用MongoDB存储游戏用户信息，用户的装备、积分等直接以内嵌文档的形式存储，方便直接查询、更新。 物流场景：使用MongoDB存储订单信息，订单状态在运行过程中会不断更新，以MongoDB内嵌数据的形式来存储，一次查询就能将订单所有的变更信息读出来。 社交场景：使用MongoDB存储用户信息，以及用户发布的朋友圈信息，通过地理位置索引实现附近的人、地点等功能。物联网场景：使用MongoDB存储所有接入的智能设备，以及设备汇报的日志信息，并对这些信息进行多维度的分析。 直播：使用MongoDB存储用户信息、礼物信息等。","categories":[{"name":"技术","slug":"技术","permalink":"https://jiang-shijie826.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"技术","slug":"技术","permalink":"https://jiang-shijie826.github.io/tags/%E6%8A%80%E6%9C%AF/"}]},{"title":"批量插入10万+条数据优化过程","slug":"批量插入10万-条数据优化过程","date":"2023-06-14T06:53:13.000Z","updated":"2025-03-21T02:16:26.190Z","comments":true,"path":"2023/06/14/批量插入10万-条数据优化过程/","permalink":"https://jiang-shijie826.github.io/2023/06/14/%E6%89%B9%E9%87%8F%E6%8F%92%E5%85%A510%E4%B8%87-%E6%9D%A1%E6%95%B0%E6%8D%AE%E4%BC%98%E5%8C%96%E8%BF%87%E7%A8%8B/","excerpt":"","text":"在使用mybatis插入大量数据的时候,为了提高效率,放弃循环插入,改为批量插入,mapper如下: 1234567891011public interface TestMapper &#123; @Insert(&quot;&lt;script&gt;&quot; + &quot;insert into test (t1,t2,t3,t4,t5) values &quot; + &quot;&lt;foreach collection=&#x27;list&#x27; item=&#x27;obj&#x27; separator=&#x27;,&#x27;&gt;&quot; + &quot;(#&#123;obj.t1&#125;,#&#123;obj.t2&#125;,#&#123;obj.t3&#125;,#&#123;obj.t4&#125;,#&#123;obj.t5&#125;)&quot; + &quot;&lt;/foreach&gt;&quot; + &quot;&lt;/script&gt;&quot;) Integer testBatchInsert(List&lt;TestVO&gt; list); &#125; 实体类: 123456789101112131415@Data@NoArgsConstructor@AllArgsConstructorpublic class TestVO &#123; private String t1; private String t2; private String t3; private String t4; private String t5; &#125; 测试类如下: 1234567891011121314151617@SpringBootTest(classes = TestApplication.class)@RunWith(SpringRunner.class)public class TestDemo &#123; @Autowired private TestMapper testMapper; @Test public void insert() &#123; List&lt;TestVO&gt; list = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 200000; i++) &#123; list.add(new TestVO(i + &quot;,&quot; + i, i + &quot;,&quot; + i, i + &quot;,&quot; + i, i + &quot;,&quot; + i, i + &quot;,&quot; + i)); &#125; System.out.println(testMapper.testBatchInsert(list)); &#125; &#125; 为了复现bug,我限制了JVM内存: 执行测试类报错如下: 123java.lang.OutOfMemoryError: Java heap space at java.base/java.util.Arrays.copyOf(Arrays.java:3746) 可以看到,Arrays在申请内存的时候,导致栈内存溢出 改进方法,分批新增: 123456789101112131415161718192021@SpringBootTest(classes = TestApplication.class)@RunWith(SpringRunner.class)public class TestDemo &#123; @Autowired private TestMapper testMapper; @Test public void insert() &#123; List&lt;TestVO&gt; list = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 200000; i++) &#123; list.add(new TestVO(i + &quot;,&quot; + i, i + &quot;,&quot; + i, i + &quot;,&quot; + i, i + &quot;,&quot; + i, i + &quot;,&quot; + i)); &#125; int index = list.size() / 10000; for (int i=0;i&lt; index;i++)&#123; //stream流表达式，skip表示跳过前i*10000条记录，limit表示读取当前流的前10000条记录 testMapper.testBatchInsert(list.stream().skip(i*10000).limit(10000).collect(Collectors.toList())); &#125; &#125; &#125; 有一种方法是调高JVM内存,不过不建议使用,不仅吃内存,而且数据量过大会导致sql过长报错. 另附存储过程循环插入: 123456789101112131415161718192021222324DROP PROCEDURE IF EXISTS pdu_loop;create procedure pdu_loop(a int)begin declare i int default 1; -- 循环开始 loop_name:loop if i&gt;a then -- 判断条件成立则结束循环 leave loop_name; end if; -- start 往表添加数据 INSERT INTO `scs_test2`.`scs_exrate_system_d`(`tenantsid`, `exrate_system_no`, `effective_date`, `source_currency`, `target_currency`, `exrate_decimal_place`, `direct_quotation_exrate`, `indirect_quotation_exrate`, `average_exrate`, `manage_status`, `create_date`, `create_by`, `modified_date`, `modified_by`) VALUES (485743257928256, i, &#x27;2022-12-12 12:12:12&#x27;, &#x27;jsj&#x27;, &#x27;003&#x27;, 2, 6.9900000000, 7.9900000000, NULL, &#x27;Y&#x27;, &#x27;2023-06-12 01:03:45&#x27;, &#x27;ScsQCTest001&#x27;, NULL, NULL); -- end set i=i+1;-- 循环结束 end loop; -- start输出结果select * from scs_exrate_system_d where source_currency=&#x27;jsj&#x27;;-- end end; -- 执行存储过程call pdu_loop(5);","categories":[{"name":"数据优化","slug":"数据优化","permalink":"https://jiang-shijie826.github.io/categories/%E6%95%B0%E6%8D%AE%E4%BC%98%E5%8C%96/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://jiang-shijie826.github.io/tags/mysql/"}]},{"title":"VUE3实现组件刷新","slug":"VUE3实现组件刷新","date":"2023-05-31T05:54:08.000Z","updated":"2023-05-31T06:02:29.226Z","comments":true,"path":"2023/05/31/VUE3实现组件刷新/","permalink":"https://jiang-shijie826.github.io/2023/05/31/VUE3%E5%AE%9E%E7%8E%B0%E7%BB%84%E4%BB%B6%E5%88%B7%E6%96%B0/","excerpt":"","text":"VUE3中实现组件刷新 provide ： 向子组件以及子孙组件传递数据。接收两个参数，第一个参数是 key，即数据的名称；第二个参数为 value，即数据的值inject ： 接收父组件或祖先组件传递过来的数据。接收一个参数 key，即父组件或祖先组件传递的数据名称 通过依赖注入（provide和inject）实现自定义页面刷新事件 原理： 给app.vue中router-view绑定v-if事件，在函数中控制v-if的值在短时间内由true到false再到true,从而使页面达到刷新效果 刷新实现 APP.VUE 12345678910111213141516&lt;script setup&gt;import &#123; RouterView &#125; from &#x27;vue-router&#x27;import &#123; ref, provide, nextTick &#125; from &#x27;vue&#x27;const isRouterActive = ref(true)provide(&#x27;reload&#x27;, () =&gt; &#123; isRouterActive.value = false nextTick(() =&gt; &#123; isRouterActive.value = true &#125;)&#125;)&lt;/script&gt;&lt;template&gt; &lt;router-view v-if=&quot;isRouterActive&quot;&gt;&lt;/router-view&gt;&lt;/emplate&gt; 刷新页面需要用到刷新事件的子组件： 12345678910111213&lt;script lang=&quot;ts&quot; setup&gt;import &#123; reactive, inject &#125; from &#x27;vue&#x27;//刷新页面//注入刷新事件,这里括号中的参数要对应上前面provide中的第一个参数 const reload: any = inject(&#x27;reload&#x27;)const jump = (item: any) =&gt; &#123; .... .... reload(); .... ....&#125;&lt;/script&gt;","categories":[{"name":"技术","slug":"技术","permalink":"https://jiang-shijie826.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"VUE3","slug":"VUE3","permalink":"https://jiang-shijie826.github.io/tags/VUE3/"}]},{"title":"vue3复制功能实现（vue-clipboard3）","slug":"vue3复制功能实现（vue-clipboard3）","date":"2023-05-26T05:56:45.000Z","updated":"2023-05-26T06:25:12.203Z","comments":true,"path":"2023/05/26/vue3复制功能实现（vue-clipboard3）/","permalink":"https://jiang-shijie826.github.io/2023/05/26/vue3%E5%A4%8D%E5%88%B6%E5%8A%9F%E8%83%BD%E5%AE%9E%E7%8E%B0%EF%BC%88vue-clipboard3%EF%BC%89/","excerpt":"","text":"安装 vue-clipboard3 1$ npm install --save vue-clipboard3 在 setup () &#123;&#125; 中使用： 1234567891011121314151617181920212223242526272829303132333435&lt;template&gt; &lt;button @click=&quot;touchCopy&quot;&gt;复制链接&lt;/button&gt;&lt;/template&gt;&lt;script&gt;import &#123; defineComponent &#125; from &#x27;vue&#x27;// 导入插件import useClipboard from &#x27;vue-clipboard3&#x27;export default defineComponent(&#123; setup () &#123; // 点击复制 function touchCopy () &#123; // 调用 copy(&#x27;拷贝内容&#x27;) &#125; // 使用插件 const &#123; toClipboard &#125; = useClipboard() const copy = async (msg) =&gt; &#123; try &#123; // 复制 await toClipboard(msg) // 复制成功 &#125; catch (e) &#123; // 复制失败 &#125; &#125; // 导出 return &#123; // 点击复制 touchCopy &#125; &#125;&#125;)&lt;/script&gt; 在 &lt;script setup&gt; 中使用： 12345678910111213141516171819202122232425&lt;template&gt; &lt;button @click=&quot;touchCopy&quot;&gt;复制链接&lt;/button&gt;&lt;/template&gt;&lt;script setup&gt;// 导入插件import useClipboard from &#x27;vue-clipboard3&#x27;// 点击复制function touchCopy () &#123; // 调用 copy(&#x27;拷贝内容&#x27;)&#125;// 使用插件const &#123; toClipboard &#125; = useClipboard()const copy = async (msg) =&gt; &#123; try &#123; // 复制 await toClipboard(msg) // 复制成功 &#125; catch (e) &#123; // 复制失败 &#125;&#125;&lt;/script&gt;","categories":[{"name":"技术","slug":"技术","permalink":"https://jiang-shijie826.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"vue","slug":"vue","permalink":"https://jiang-shijie826.github.io/tags/vue/"}]},{"title":"Hexo部署步骤","slug":"Hexo部署步骤","date":"2023-05-26T05:53:36.000Z","updated":"2025-03-21T02:31:03.939Z","comments":true,"path":"2023/05/26/Hexo部署步骤/","permalink":"https://jiang-shijie826.github.io/2023/05/26/Hexo%E9%83%A8%E7%BD%B2%E6%AD%A5%E9%AA%A4/","excerpt":"","text":"每次部署的步骤，可按以下三步来进行 123npx hexo cleannpx hexo generatenpx hexo deploy 一些常用命令： 1234567npx hexo new &quot;postName&quot; #新建文章npx hexo new page &quot;pageName&quot; #新建页面npx hexo generate #生成静态页面至public目录npx hexo server #开启预览访问端口（默认端口4000，&#x27;ctrl + c&#x27;关闭server）npx hexo deploy #将.deploy目录部署到GitHubnpx hexo help # 查看帮助npx hexo version #查看Hexo的版本 网络图片不显示在标题下面添加以下内容 1&lt;meta name=&quot;referrer&quot; content=&quot;no-referrer&quot;/&gt;","categories":[{"name":"趣味","slug":"趣味","permalink":"https://jiang-shijie826.github.io/categories/%E8%B6%A3%E5%91%B3/"}],"tags":[{"name":"技术","slug":"技术","permalink":"https://jiang-shijie826.github.io/tags/%E6%8A%80%E6%9C%AF/"}]},{"title":"XML文件或者字符串转Bean对象","slug":"XML文件或者字符串转Bean对象","date":"2023-03-20T03:29:56.000Z","updated":"2025-03-21T02:17:35.760Z","comments":true,"path":"2023/03/20/XML文件或者字符串转Bean对象/","permalink":"https://jiang-shijie826.github.io/2023/03/20/XML%E6%96%87%E4%BB%B6%E6%88%96%E8%80%85%E5%AD%97%E7%AC%A6%E4%B8%B2%E8%BD%ACBean%E5%AF%B9%E8%B1%A1/","excerpt":"","text":"需要的xml文件 12345678&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;&lt;myDocument&gt; &lt;desc&gt;sky&lt;/desc&gt; &lt;myPerson&gt; &lt;person name=&quot;sky1&quot; age=&quot;18&quot;/&gt; &lt;person name=&quot;sky2&quot; age=&quot;19&quot;/&gt; &lt;/myPerson&gt;&lt;/myDocument&gt; 基本步骤 定义好各个xml元素对应的javabean，在类上加注解@XmlRootElement(name &#x3D; “xxx”) 在各个子元素对应的java字段上（如desc、myPerson）加注解 @XmlElement(name &#x3D; “xxx”) 其中person的xml标签比较特殊，具有name和age这2个属性，需要做特殊处理：不能直接在name字段上加注解，而是需要先建立set或者get方法，在方法上加注解@XmlAttribute(name &#x3D; “xxx”) 1234567@XmlRootElement(name = &quot;myDocument&quot;)public class MyDocument&#123; @XmlElement(name = &quot;desc&quot;) private String desc; @XmlElement(name = &quot;myPerson&quot;) private MyPerson myPerson;&#125; 12345678910111213@XmlRootElement(name = &quot;person&quot;)public class Person&#123; private String name; private int age; @XmlAttribute(name = &quot;name&quot;) public void setName(String name) &#123; this.name = name; &#125; @XmlAttribute(name = &quot;age&quot;) public void setAge(int age) &#123; this.age = age; &#125;&#125; 12345@XmlRootElement(name = &quot;myPerson&quot;)class MyPerson&#123; @XmlElement(name = &quot;person&quot;) private List&lt;Person&gt; person;&#125; 测试： 1234567891011121314151617181920public class TestXml &#123; public static void main(String[] args) throws Exception&#123; String xml = &quot;&lt;?xml version=\\&quot;1.0\\&quot; encoding=\\&quot;utf-8\\&quot;?&gt;\\n&quot; + &quot;&lt;myDocument&gt;\\n&quot; + &quot; &lt;desc&gt;sky&lt;/desc&gt;\\n&quot; + &quot; &lt;myPerson&gt;\\n&quot; + &quot; &lt;person name=\\&quot;sky1\\&quot; age=\\&quot;18\\&quot;/&gt;\\n&quot; + &quot; &lt;person name=\\&quot;sky2\\&quot; age=\\&quot;19\\&quot;/&gt;\\n&quot; + &quot; &lt;/myPerson&gt;\\n&quot; + &quot;&lt;/myDocument&gt;&quot;; JAXBContext context = JAXBContext.newInstance(MyDocument.class); Unmarshaller unmarshaller = context.createUnmarshaller(); StringReader sr = new StringReader(xml); MyDocument myDocument = (MyDocument) unmarshaller.unmarshal(sr); System.out.println(myDocument); &#125;&#125; 图解：","categories":[{"name":"技术","slug":"技术","permalink":"https://jiang-shijie826.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://jiang-shijie826.github.io/tags/Java/"}]},{"title":"有趣的排序算法","slug":"有趣的排序算法","date":"2023-03-16T02:52:52.000Z","updated":"2023-03-16T02:54:51.010Z","comments":true,"path":"2023/03/16/有趣的排序算法/","permalink":"https://jiang-shijie826.github.io/2023/03/16/%E6%9C%89%E8%B6%A3%E7%9A%84%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/","excerpt":"","text":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115/*** 二分查找法* @param nums 查找的数组* @param target 目标值* @return 返回数组下标*/public static int binarySearch(int[] nums, int target) &#123; int left = 0; int right = nums.length - 1; while (left &lt;= right) &#123; int mid = (left + right) / 2; if (nums[mid] == target) &#123; return mid; &#125; else if (nums[mid] &lt; target) &#123; left = mid + 1; &#125; else if (nums[mid] &gt; target) &#123; right = mid - 1; &#125; &#125; return -1;&#125;/** * 冒泡排序 * @param nums 需要排序的数组 */public static void bubbleSort(int[] nums) &#123; int size = nums.length; for(int i = 0; i &lt; size - 1; i++)&#123; for (int j = 0; j &lt; size - 1 - i; j++)&#123; if (nums[j] &gt; nums[j + 1]) &#123; int temp = nums[j]; nums[j] = nums[j + 1]; nums[j + 1] = temp; &#125; &#125; &#125;&#125;/** * 选择排序 * @param nums 需要排序的数组 */public static void selectionSort(int[] nums) &#123; for (int i = 0; i &lt; nums.length - 1; i++) &#123; for (int j = i + 1; j &lt; nums.length; j++)&#123; if (nums[j] &lt; nums[i]) &#123; int temp = nums[i]; nums[i] = nums[j]; nums[j] = temp; &#125; &#125; &#125;&#125;/** * 插入排序 * @param arr 需要排序的数组 */public static void insertSort(int[] arr)&#123; for (int i = 1; i &lt; arr.length; i++) &#123; for (int j = i - 1; j &gt;= 0; j--) &#123; if (arr[j] &gt; arr[j + 1]) &#123; int temp = arr[j]; arr[j] = arr[j + 1]; arr[j + 1] = temp; &#125;else &#123; break; &#125; &#125; &#125;&#125;/** * 快速排序 * @param nums 需要排序的数组 * @param start 序列最左边 * @param end 序列最右边 */public static void quickSort(int[] nums, int start, int end) &#123; if (start &gt; end) &#123; return; &#125; int i, j, base; i = start; j = end; base = nums[start]; while (i &lt; j) &#123; while (i &lt; j &amp;&amp; nums[j] &gt;= base) &#123; j--; &#125; while (i &lt; j &amp;&amp; nums[i] &lt;= base) &#123; i++; &#125; if ( i &lt; j) &#123; swap(nums, i, j); &#125; &#125; swap(nums, start, i); quickSort(nums, start, j-1); quickSort(nums, j+1, end);&#125;/** * 交换左右数值 * @param nums 数组 * @param left 左边的索引 * @param right 右边的索引 */public static void swap(int[] nums, int left, int right) &#123; int temp = nums[left]; nums[left] = nums[right]; nums[right] = temp;&#125;","categories":[{"name":"算法","slug":"算法","permalink":"https://jiang-shijie826.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"排序","slug":"排序","permalink":"https://jiang-shijie826.github.io/tags/%E6%8E%92%E5%BA%8F/"}]},{"title":"有趣的博客之旅!","slug":"有趣的博客之旅","date":"2023-03-03T08:29:13.000Z","updated":"2023-03-03T08:39:28.867Z","comments":true,"path":"2023/03/03/有趣的博客之旅/","permalink":"https://jiang-shijie826.github.io/2023/03/03/%E6%9C%89%E8%B6%A3%E7%9A%84%E5%8D%9A%E5%AE%A2%E4%B9%8B%E6%97%85/","excerpt":"","text":"Today you do things others don’t do. Tomorrow you do things others can’t do. – 今天你做别人不做的事，明天你做别人做不到的事。 “人们总是容易高估一天的影响，而低估长期的影响”。比如学英语、写作，可能努力了一个月都没有效果，很多人就开始放弃了，转而去寻找其他的方法。但有些人坚持了下来，于是这些人坚持了一年、两年甚至几年之后，最后到达了很高的高度，才发现原来每一天的坚持都没有浪费，最后都是有效果的。 1. 减少任务切换，提高做事情的效率 提高做事情的效率，最好的办法就是进入“心流”的状态。不管是写代码、写文字还是看书学习，在“心流”的状态下，效率比平时要提高好几倍。 “心流”的状态，就是一种忘我的境界，忘记了时间、忘记了周围所处的环境，甚至忘记了身体上的痛苦，专心沉浸在当下所做的事情上。我相信这种状态，大家多多少少都有体会，比如在废寝忘食打游戏的时候。这种状态下，人所爆发出来的潜能是巨大的。 要达到“心流”的状态，最简单易行的方法，就是减少任务的切换。就像CPU线程切换，需要缓存上一个任务的执行状态，加载下一个任务的运行环境，效率很低。人脑也是，在上下文切换的时候，需要耗费很多的时间和精力。 而工作中，经常会被工作软件的消息提醒所打断，很难进入”心流“状态。比如，正在尝试解决一个疑难的问题，但是突然来了一条工作上的消息，于是不得不中断当前的工作，去看这个消息。等处理完消息后，在回到工作，可能已经忘记之前做到哪里了，又需要花时间才能重新进入状态。 可以尝试”番茄钟”的方法。在每个番茄钟开始的时候，屏蔽消息，集中精神工作25分钟，然后再花5分钟处理这25分钟到达的消息。处理完后，进入下一个番茄钟。 2. 不要给自己定太高的目标 3. 先写起来，自然而然就会有进步 第一个就是不管怎么样，不管写得有多烂，先写起来，以量变来引起质变。我现在的写作量，可能连那些大V一个月的量都不到，凭什么觉得自己的水平就能和人家一样。如果每天输出500字，一年就是18.25万字。坚持写，我相信写一年之后，水平肯定会有进步。 没有什么是刻意练习不能达成的，如果有，那肯定是练习不够多。 4. 多看多模仿 写文章也是有方法可以借鉴的。去看好的文章是什么样的，向优秀的文章和作者学习。 比如，我之前看一个技术博主，会在每篇文章的开头放一个脑图，描述整片文章的整体架构，我觉得这个方法就很好。首先自己可以根据这篇脑图往里填充资料，速度更快也更清晰，同时，读者也可以在看文章之前对文章的内容有一个整体的感知，很快就能定位到自己需要的内容上。之后我的文章也可以借鉴这个方法。 可以从以下几个方面去尝试： 1. 提前想一些topic，主动积累 在开始写博客之前，提前收集一些topic。我现在就有一个文档，专门用来放我想写的文章topic，现在这个文档里面已经有几十个可以写的topic了。 提前脑暴一些topic，或者列一个知识图谱，到时候如果发现没什么内容可写，直接去list里面找一个topic就好了。 2. 主动去学习一些新的东西 对于一些业务开发的同学，可以在开发之余，主动push自己去学一些新的技术。比如看一些技术书籍和博客。","categories":[{"name":"技术","slug":"技术","permalink":"https://jiang-shijie826.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"博客","slug":"博客","permalink":"https://jiang-shijie826.github.io/tags/%E5%8D%9A%E5%AE%A2/"}]},{"title":"项目经历需要注意的地方","slug":"项目经历需要注意的地方","date":"2023-03-03T07:59:06.000Z","updated":"2023-03-03T08:03:11.353Z","comments":true,"path":"2023/03/03/项目经历需要注意的地方/","permalink":"https://jiang-shijie826.github.io/2023/03/03/%E9%A1%B9%E7%9B%AE%E7%BB%8F%E5%8E%86%E9%9C%80%E8%A6%81%E6%B3%A8%E6%84%8F%E7%9A%84%E5%9C%B0%E6%96%B9/","excerpt":"","text":"项目经历是介绍你实战经历的地方，同时也能反映你对已掌握的技能的使用情况。对于应聘偏技术类的岗位来说，这块非常的重要。 下面会以支付中心作为例子进行阐述。 项目背景，也即是你一定要非常清楚启动这个项目的缘由是啥。如果这个都说不清楚的话，那说明，你真的就是埋头干活，偏执行的角色。对项目并没有一个整体的认识。就算你只是这个项目的普通参与者，也需要主动的去了解和理解该项目立项的原因。有个注意的地方是，项目背景的文字描述不要太长，一两句就可以了。比如说：当前支付中心耦合在订单系统中，为了提升支付模块的稳定性、维护性、性能和扩展性，需要将支付模块独立出来，统一为其他内部系统提供支付能力; 项目功能介绍，介绍一下这个项目能做什么，有什么核心模块，需要应付什么量级的流量。以支付中心为例子：为内部的订单系统提供支付能力，对内提供了微信、支付宝、抖音、海外、信用卡、钱包、礼品卡以及组合支付的支付、回调、退款、查询、业务对账等能力。平时需要应付每秒1万的支付请求。 技术架构设计，这里考察的是技术选型的严谨性和模块设计的合理性。如果项目用到了RabbitMQ、Redis、Kafka等一些技术，你自己心里一定有个底，就是当时为什么选用这些技术，是经过深思熟虑的吗？是经过了很多轮的技术栈对比后决定使用的吗。也即是技术选型是一个严谨的论证的一个过程。而设计这块，则要说清楚模块划分的缘由以及解决方案。还是以支付中心为例子：通过支付网关，对外提供统一的接口，而内部则通过支付路由模块，进行具体的支付方式路由，并把单独的支付方式，以物理单元进行隔离，避免各种支付方式在出故障时，相互影响。为了应付高频的支付动作，采用数据库分库的方式缓解写的压力。 我负责的模块，如果你参与的项目是部门核心项目，但是自己参与的模块确是边缘模块或者只是参与了很小的一部分，虽然你也能在这个项目里，得到成长。但是那是称不上个人亮点的。因为面试官会更倾向于：你为这个项目做了什么贡献，因为你，项目有了什么好的改变和突破性进展。因此，做项目的时候，不妨跟自己的领导多反馈一下，希望能独立主导一些重要的模块。如果领导觉得当前的你还无法独立hold住重要的模块，你也不要气馁，平时多多提升自己，争取后续能主导一些重要模块。这个真的很重要，为了将来的自己，你必须得这么做。在做项目的时候，如果你长期一直起着螺丝钉的作用的话，对你极其不利，甚至可以说，你是在浪费时间。 难点和踩过的坑，难点也即是亮点。在你负责的模块里，具体的难点是什么，你是通过什么方案解决的。而解决的过程中，又遇到什么大坑？怎么优化的。这个其实是一种引导，把面试官引入到你自己比较熟悉又印象深刻的领域，如果你准备充分的话，是能给面试官一个好的印象的，是能加分的。同时能解决掉难点，对自身成长也是有利的，且还能说明的你韧性不错，有追求。 取得的成效，不能只是重视过程，而不重视结果，这是不可取的。你需要用结果和数据体现你的价值。比如说，支付中心上线后，你负责的业务模块，慢调用和慢SQL消失了，接口响应速度提升了10倍，上线半年，无任何大故障。等等。 项目经历写几个合适？如果按照上面的的方式来书写项目的话，那每个项目的文字描述是不短的，一个项目的描述就大概要占用半页了。因此，简历里的项目不能太多，2到3个就可以了。项目主要在精不在多，把自己负责比较多的且能作为自己的一个亮点的核心项目，说清楚道明白，更为重要。","categories":[{"name":"简历","slug":"简历","permalink":"https://jiang-shijie826.github.io/categories/%E7%AE%80%E5%8E%86/"}],"tags":[{"name":"项目","slug":"项目","permalink":"https://jiang-shijie826.github.io/tags/%E9%A1%B9%E7%9B%AE/"}]},{"title":"查看SQL执行计划(explain)","slug":"查看SQL执行计划-explain","date":"2023-03-03T06:23:59.000Z","updated":"2023-03-03T06:56:59.256Z","comments":true,"path":"2023/03/03/查看SQL执行计划-explain/","permalink":"https://jiang-shijie826.github.io/2023/03/03/%E6%9F%A5%E7%9C%8BSQL%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92-explain/","excerpt":"","text":"查看SQL执行计划**explain：**explain select * from xxx 当使用explain sql后会看到执行计划 字段 解释 id 每个被独立执行的操作标识，标识对象被操作的顺序，id值越大，先被执行，如果相同，执行顺序从上到下 select_type 查询中每个select 字句的类型 table 被操作的对象名称，通常是表名，但有其他格式 partitions 匹配的分区信息(对于非分区表值为NULL) type 连接操作的类型 possible_keys 可能用到的索引 key 优化器实际使用的索引(最重要的列) 从最好到最差的连接类型为const、eq_reg、ref、range、index和ALL。当出现ALL时表示当前SQL出现了“坏味道” key_len 被优化器选定的索引键长度，单位是字节 ref 表示本行被操作对象的参照对象，无参照对象为NULL rows 查询执行所扫描的元组个数（对于innodb，此值为估计值） filtered 条件表上数据被过滤的元组个数百分比 extra 执行计划的重要补充信息，当此列出现Using filesort , Using temporary 字样时就要小心了，很可能SQL语句需要优化 SQL优化小结这里给大家总结一下优化SQL的套路 查看执行计划 explain 如果有告警信息，查看告警信息 show warnings; 查看SQL涉及的表结构和索引信息 根据执行计划，思考可能的优化点 按照可能的优化点执行表结构变更、增加索引、SQL改写等操作 查看优化后的执行时间和执行计划 如果优化效果不明显，重复第四步操作","categories":[{"name":"SQL优化","slug":"SQL优化","permalink":"https://jiang-shijie826.github.io/categories/SQL%E4%BC%98%E5%8C%96/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://jiang-shijie826.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"}]},{"title":"数据库中DML、DDL、DCL的含义及区别","slug":"数据库中DML、DDL、DCL的含义及区别","date":"2023-03-03T02:47:25.000Z","updated":"2023-03-03T02:59:06.289Z","comments":true,"path":"2023/03/03/数据库中DML、DDL、DCL的含义及区别/","permalink":"https://jiang-shijie826.github.io/2023/03/03/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%ADDML%E3%80%81DDL%E3%80%81DCL%E7%9A%84%E5%90%AB%E4%B9%89%E5%8F%8A%E5%8C%BA%E5%88%AB/","excerpt":"","text":"数据库管理系统软件是一种操纵和管理数据库的大型软件。 其功能包括数据库定义、数据操纵、数据库的运行管理、数据库建立和维护等。 数据库应用程序是指以数据库为基础，用VB或其他开发工具开发的、实现某种具体功能的程序。 一、DML与DDL的含义： 1、DML（Data Manipulation Language）数据操作语言-数据库的基本操作，SQL中处理数据等操作统称为数据操纵语言,简而言之就是实现了基本的“增删改查”操作。包括的关键字有：select、update、delete、insert、merge 2、DDL（Data Definition Language）数据定义语言-用于定义和管理 SQL 数据库中的所有对象的语言，对数据库中的某些对象(例如，database,table)进行管理。包括的关键字有： create、alter、drop、truncate、comment、grant、revoke 二、DML与DDL的区别： 1.DML操作是可以手动控制事务的开启、提交和回滚的。 2.DDL操作是隐性提交的，不能rollback！","categories":[{"name":"技术","slug":"技术","permalink":"https://jiang-shijie826.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://jiang-shijie826.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"}]},{"title":"趣味赛跑","slug":"趣味赛跑","date":"2023-03-02T06:27:45.000Z","updated":"2023-03-02T06:29:48.876Z","comments":true,"path":"2023/03/02/趣味赛跑/","permalink":"https://jiang-shijie826.github.io/2023/03/02/%E8%B6%A3%E5%91%B3%E8%B5%9B%E8%B7%91/","excerpt":"","text":"我：为什么你的键盘这么响？ 开发者：我是一名C++开发人员。 我：那又怎样！我是一名python开发人员。 开发者：你太懒了！你不知道C++是强类型（strongly typed）的吗？","categories":[{"name":"生活","slug":"生活","permalink":"https://jiang-shijie826.github.io/categories/%E7%94%9F%E6%B4%BB/"}],"tags":[{"name":"趣味","slug":"趣味","permalink":"https://jiang-shijie826.github.io/tags/%E8%B6%A3%E5%91%B3/"}]}],"categories":[{"name":"技术","slug":"技术","permalink":"https://jiang-shijie826.github.io/categories/%E6%8A%80%E6%9C%AF/"},{"name":"数据库","slug":"数据库","permalink":"https://jiang-shijie826.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"数据优化","slug":"数据优化","permalink":"https://jiang-shijie826.github.io/categories/%E6%95%B0%E6%8D%AE%E4%BC%98%E5%8C%96/"},{"name":"趣味","slug":"趣味","permalink":"https://jiang-shijie826.github.io/categories/%E8%B6%A3%E5%91%B3/"},{"name":"算法","slug":"算法","permalink":"https://jiang-shijie826.github.io/categories/%E7%AE%97%E6%B3%95/"},{"name":"简历","slug":"简历","permalink":"https://jiang-shijie826.github.io/categories/%E7%AE%80%E5%8E%86/"},{"name":"SQL优化","slug":"SQL优化","permalink":"https://jiang-shijie826.github.io/categories/SQL%E4%BC%98%E5%8C%96/"},{"name":"生活","slug":"生活","permalink":"https://jiang-shijie826.github.io/categories/%E7%94%9F%E6%B4%BB/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"https://jiang-shijie826.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"MySQL","slug":"MySQL","permalink":"https://jiang-shijie826.github.io/tags/MySQL/"},{"name":"技术","slug":"技术","permalink":"https://jiang-shijie826.github.io/tags/%E6%8A%80%E6%9C%AF/"},{"name":"mysql","slug":"mysql","permalink":"https://jiang-shijie826.github.io/tags/mysql/"},{"name":"VUE3","slug":"VUE3","permalink":"https://jiang-shijie826.github.io/tags/VUE3/"},{"name":"vue","slug":"vue","permalink":"https://jiang-shijie826.github.io/tags/vue/"},{"name":"Java","slug":"Java","permalink":"https://jiang-shijie826.github.io/tags/Java/"},{"name":"排序","slug":"排序","permalink":"https://jiang-shijie826.github.io/tags/%E6%8E%92%E5%BA%8F/"},{"name":"博客","slug":"博客","permalink":"https://jiang-shijie826.github.io/tags/%E5%8D%9A%E5%AE%A2/"},{"name":"项目","slug":"项目","permalink":"https://jiang-shijie826.github.io/tags/%E9%A1%B9%E7%9B%AE/"},{"name":"数据库","slug":"数据库","permalink":"https://jiang-shijie826.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"趣味","slug":"趣味","permalink":"https://jiang-shijie826.github.io/tags/%E8%B6%A3%E5%91%B3/"}]}