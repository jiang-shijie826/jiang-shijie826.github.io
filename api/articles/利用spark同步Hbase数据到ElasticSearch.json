{"title":"利用spark同步Hbase数据到ElasticSearch","slug":"利用spark同步Hbase数据到ElasticSearch","date":"2025-03-21T01:52:17.000Z","updated":"2025-03-21T02:12:49.536Z","comments":true,"path":"api/articles/利用spark同步Hbase数据到ElasticSearch.json","excerpt":null,"covers":["/2025/03/21/%E5%88%A9%E7%94%A8spark%E5%90%8C%E6%AD%A5Hbase%E6%95%B0%E6%8D%AE%E5%88%B0ElasticSearch/image-20250321100343192.png","/2025/03/21/%E5%88%A9%E7%94%A8spark%E5%90%8C%E6%AD%A5Hbase%E6%95%B0%E6%8D%AE%E5%88%B0ElasticSearch/image-20250320172304319.png","/2025/03/21/%E5%88%A9%E7%94%A8spark%E5%90%8C%E6%AD%A5Hbase%E6%95%B0%E6%8D%AE%E5%88%B0ElasticSearch/image-20250320172907896.png","/2025/03/21/%E5%88%A9%E7%94%A8spark%E5%90%8C%E6%AD%A5Hbase%E6%95%B0%E6%8D%AE%E5%88%B0ElasticSearch/image-20250320173103194.png","/2025/03/21/%E5%88%A9%E7%94%A8spark%E5%90%8C%E6%AD%A5Hbase%E6%95%B0%E6%8D%AE%E5%88%B0ElasticSearch/image-20250320174118378.png"],"content":"<h2><span id=\"利用spark同步hbase数据到elasticsearch\">利用spark同步Hbase数据到ElasticSearch</span></h2><hr>\n<p><strong>主要实现思路:利用spark-submit 命令 + Scala 代码(亲测:同步10万条数据,38s左右)</strong></p>\n<p>具体实现步骤如下:</p>\n<h5><span id=\"1安装hadoop-habse-zooker-sacla-spark\">1.安装hadoop、habse、zooker、sacla、spark</span></h5><p>参考此篇博客进行搭建:</p>\n<p>[<a href=\"https://blog.csdn.net/qq_51235856/article/details/125712898]\">https://blog.csdn.net/qq_51235856/article/details/125712898]</a>: </p>\n<h5><span id=\"2编写同步jar包利用scala语言编写项目打包成jar上传到服务器\">2.编写同步jar包(利用scala语言，编写项目，打包成jar，上传到服务器)</span></h5><ul>\n<li><p>Idea中安装Scala插件</p>\n<img src=\"/2025/03/21/%E5%88%A9%E7%94%A8spark%E5%90%8C%E6%AD%A5Hbase%E6%95%B0%E6%8D%AE%E5%88%B0ElasticSearch/image-20250321100343192.png\" class title=\"image-20250321100343192\">\n</li>\n<li><p>新建Scala项目</p>\n</li>\n</ul>\n<img src=\"/2025/03/21/%E5%88%A9%E7%94%A8spark%E5%90%8C%E6%AD%A5Hbase%E6%95%B0%E6%8D%AE%E5%88%B0ElasticSearch/image-20250320172304319.png\" class title=\"image-20250320172304319\">\n\n<ul>\n<li>在build.sbt中引入依赖,导入的依赖需要考虑兼容性</li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ThisBuild / version := &quot;v1&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">ThisBuild / scalaVersion := &quot;2.11.12&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">lazy val root = (project in file(&quot;.&quot;))</span><br><span class=\"line\">  .settings(</span><br><span class=\"line\">    name := &quot;spark2es&quot;,</span><br><span class=\"line\">    idePackagePrefix := Some(&quot;com.xxxx.xxxx&quot;)</span><br><span class=\"line\">  )</span><br><span class=\"line\"></span><br><span class=\"line\">libraryDependencies += &quot;org.apache.spark&quot; %% &quot;spark-core&quot; % &quot;2.4.0&quot;</span><br><span class=\"line\">libraryDependencies += &quot;org.elasticsearch&quot; %% &quot;elasticsearch-spark-20&quot; % &quot;7.17.25&quot;</span><br><span class=\"line\">libraryDependencies += &quot;org.apache.hbase&quot; % &quot;hbase-client&quot; % &quot;2.5.6&quot;</span><br><span class=\"line\">libraryDependencies += &quot;org.apache.hbase&quot; % &quot;hbase-server&quot; % &quot;2.5.6&quot;</span><br><span class=\"line\">libraryDependencies += &quot;org.apache.hbase.connectors.spark&quot; % &quot;hbase-spark&quot; % &quot;1.0.0&quot;</span><br><span class=\"line\">libraryDependencies += &quot;org.apache.spark&quot; %% &quot;spark-sql&quot; % &quot;2.4.0&quot;</span><br><span class=\"line\">libraryDependencies += &quot;com.alibaba&quot; % &quot;fastjson&quot; % &quot;1.2.77&quot;</span><br><span class=\"line\">libraryDependencies += &quot;org.apache.hbase&quot; % &quot;hbase-mapreduce&quot; % &quot;2.5.6&quot;</span><br><span class=\"line\">libraryDependencies += &quot;org.scala-lang&quot; % &quot;scala-library&quot; % &quot;2.11.12&quot;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><p>新建scala文件</p>\n<img src=\"/2025/03/21/%E5%88%A9%E7%94%A8spark%E5%90%8C%E6%AD%A5Hbase%E6%95%B0%E6%8D%AE%E5%88%B0ElasticSearch/image-20250320172907896.png\" class title=\"image-20250320172907896\">\n</li>\n<li><p>编写文件</p>\n</li>\n</ul>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">object</span> <span class=\"title\">HBaseToElasticsearchMultipleTables</span> </span>&#123;</span><br><span class=\"line\">  <span class=\"keyword\">private</span> <span class=\"keyword\">final</span> <span class=\"keyword\">val</span> logger: <span class=\"type\">Logger</span> = <span class=\"type\">Logger</span>.getLogger(<span class=\"type\">HBaseToElasticsearchMultipleTables</span>.getClass)</span><br><span class=\"line\">  logger.setLevel(<span class=\"type\">Level</span>.<span class=\"type\">DEBUG</span>)</span><br><span class=\"line\">\t</span><br><span class=\"line\">  <span class=\"comment\">//定义Hbase中需要同步的表</span></span><br><span class=\"line\">  <span class=\"keyword\">private</span> <span class=\"keyword\">val</span> parserMapping: <span class=\"type\">Map</span>[<span class=\"type\">String</span>, <span class=\"type\">Result</span> =&gt; <span class=\"type\">Map</span>[<span class=\"type\">String</span>, <span class=\"type\">String</span>]] = <span class=\"type\">Map</span>(</span><br><span class=\"line\">    <span class=\"string\">&quot;student&quot;</span> -&gt; parsestudent,</span><br><span class=\"line\">\t....更多数据</span><br><span class=\"line\">  )</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"comment\">// 定义多个表和对应的索引</span></span><br><span class=\"line\">  <span class=\"keyword\">private</span> <span class=\"keyword\">final</span> <span class=\"keyword\">val</span> tablesAndIndexes = <span class=\"type\">Seq</span>(</span><br><span class=\"line\">    <span class=\"comment\">//student:Hbase表名 student:es索引名 atsn:列簇</span></span><br><span class=\"line\">    (<span class=\"string\">&quot;student&quot;</span>, <span class=\"string\">&quot;student&quot;</span>, <span class=\"string\">&quot;atsn&quot;</span>),</span><br><span class=\"line\">    ....更多数据</span><br><span class=\"line\">  )</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"comment\">//student</span></span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">parsestudent</span></span>(result: <span class=\"type\">Result</span>): <span class=\"type\">Map</span>[<span class=\"type\">String</span>, <span class=\"type\">String</span>] = &#123;</span><br><span class=\"line\">    <span class=\"comment\">//Hbase中的rowkey</span></span><br><span class=\"line\">    <span class=\"keyword\">val</span> rowKey = <span class=\"type\">Bytes</span>.toString(result.getRow)</span><br><span class=\"line\">    <span class=\"keyword\">val</span> userId = <span class=\"type\">Bytes</span>.toString(result.getValue(<span class=\"type\">Bytes</span>.toBytes(<span class=\"string\">&quot;atsn&quot;</span>), <span class=\"type\">Bytes</span>.toBytes(<span class=\"string\">&quot;userId&quot;</span>)))</span><br><span class=\"line\">\t....更多数据</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 构建 Elasticsearch 文档</span></span><br><span class=\"line\">    <span class=\"type\">Map</span>(</span><br><span class=\"line\">      <span class=\"comment\">//key:Es中的字段名 rowKey:Hbase的列名</span></span><br><span class=\"line\">      <span class=\"string\">&quot;key&quot;</span> -&gt; rowKey,</span><br><span class=\"line\">      <span class=\"string\">&quot;userId&quot;</span> -&gt; userId,</span><br><span class=\"line\">\t  ....更多数据</span><br><span class=\"line\">    )</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">main</span></span>(args: <span class=\"type\">Array</span>[<span class=\"type\">String</span>]): <span class=\"type\">Unit</span> = &#123;</span><br><span class=\"line\">    <span class=\"comment\">// 创建 SparkSession</span></span><br><span class=\"line\">    <span class=\"keyword\">val</span> spark = <span class=\"type\">SparkSession</span>.builder()</span><br><span class=\"line\">      .appName(<span class=\"string\">&quot;HBaseToElasticsearch&quot;</span>)</span><br><span class=\"line\">      <span class=\"comment\">//true:连接器将禁用节点发现功能</span></span><br><span class=\"line\">      .config(<span class=\"string\">&quot;spark.es.nodes.wan.only&quot;</span>, <span class=\"string\">&quot;true&quot;</span>)</span><br><span class=\"line\">      <span class=\"comment\">//指定es中id为Hbase中的rowkey,也可以由es自动生成</span></span><br><span class=\"line\">      .config(<span class=\"string\">&quot;spark.es.mapping.id&quot;</span>, <span class=\"string\">&quot;key&quot;</span>)</span><br><span class=\"line\">      <span class=\"comment\">// upsert操作</span></span><br><span class=\"line\">      .config(<span class=\"string\">&quot;spark.es.write.operation&quot;</span>, <span class=\"string\">&quot;upsert&quot;</span>) </span><br><span class=\"line\">      <span class=\"comment\">// 自动创建索引</span></span><br><span class=\"line\">      .config(<span class=\"string\">&quot;spark.es.index.auto.create&quot;</span>, <span class=\"string\">&quot;true&quot;</span>) </span><br><span class=\"line\">      .getOrCreate()</span><br><span class=\"line\">    logger.info(<span class=\"string\">&quot;Elasticsearch init Success~~~&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">val</span> startTime = <span class=\"type\">System</span>.currentTimeMillis()</span><br><span class=\"line\">    <span class=\"comment\">// HBase 配置</span></span><br><span class=\"line\">    <span class=\"keyword\">val</span> hbaseConf = <span class=\"type\">HBaseConfiguration</span>.create()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 统计同步的总条数</span></span><br><span class=\"line\">    <span class=\"keyword\">var</span> totalCount = <span class=\"number\">0</span>L;</span><br><span class=\"line\">    <span class=\"keyword\">var</span> metricsList = <span class=\"type\">List</span>.empty[<span class=\"type\">Map</span>[<span class=\"type\">String</span>, <span class=\"type\">Any</span>]]</span><br><span class=\"line\">    <span class=\"comment\">//循环遍历表和索引</span></span><br><span class=\"line\">    tablesAndIndexes.foreach &#123; <span class=\"keyword\">case</span> (hbaseTable, esIndex, family) =&gt;</span><br><span class=\"line\">      hbaseConf.set(<span class=\"type\">TableInputFormat</span>.<span class=\"type\">INPUT_TABLE</span>, hbaseTable) <span class=\"comment\">// HBase 表名</span></span><br><span class=\"line\"></span><br><span class=\"line\">      <span class=\"comment\">// 定义 Scan</span></span><br><span class=\"line\">      <span class=\"keyword\">val</span> scan = <span class=\"keyword\">new</span> <span class=\"type\">Scan</span>()</span><br><span class=\"line\">      scan.addFamily(<span class=\"type\">Bytes</span>.toBytes(family)) <span class=\"comment\">// 列族名</span></span><br><span class=\"line\"></span><br><span class=\"line\">      <span class=\"keyword\">val</span> scanStr = <span class=\"type\">Base64</span>.getEncoder.encodeToString(<span class=\"type\">ProtobufUtil</span>.toScan(scan).toByteArray)</span><br><span class=\"line\">      hbaseConf.set(<span class=\"type\">TableInputFormat</span>.<span class=\"type\">SCAN</span>, scanStr)</span><br><span class=\"line\"></span><br><span class=\"line\">      <span class=\"comment\">// 读取 HBase 数据</span></span><br><span class=\"line\">      <span class=\"keyword\">val</span> hbaseRDD = spark.sparkContext.newAPIHadoopRDD(</span><br><span class=\"line\">        hbaseConf,</span><br><span class=\"line\">        classOf[<span class=\"type\">TableInputFormat</span>],</span><br><span class=\"line\">        classOf[<span class=\"type\">ImmutableBytesWritable</span>],</span><br><span class=\"line\">        classOf[<span class=\"type\">Result</span>]</span><br><span class=\"line\">      )</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">      <span class=\"comment\">// 处理数据并转换为 Elasticsearch 格式</span></span><br><span class=\"line\">      <span class=\"keyword\">val</span> parseFunction = parserMapping.getOrElse(hbaseTable,</span><br><span class=\"line\">        <span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> <span class=\"type\">IllegalArgumentException</span>(<span class=\"string\">s&quot;未注册的表解析器: <span class=\"subst\">$hbaseTable</span>&quot;</span>))</span><br><span class=\"line\">\t <span class=\"comment\">//增加 Spark 作业的并行度,提高写入性能</span></span><br><span class=\"line\">      <span class=\"keyword\">val</span> targetPartitions = spark.sparkContext.defaultParallelism * <span class=\"number\">4</span></span><br><span class=\"line\">      logger.info(<span class=\"string\">s&quot;hbaseRDD.repartition <span class=\"subst\">$&#123;targetPartitions&#125;</span>&quot;</span>)</span><br><span class=\"line\">\t  </span><br><span class=\"line\">      <span class=\"comment\">//映射Hbase中的列名和Es中的字段名</span></span><br><span class=\"line\">      <span class=\"keyword\">val</span> esRDD = hbaseRDD.repartition(targetPartitions).mapPartitions &#123; partition =&gt;</span><br><span class=\"line\">        partition.flatMap &#123; <span class=\"keyword\">case</span> (_, result) =&gt;</span><br><span class=\"line\">          <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (result != <span class=\"literal\">null</span>) <span class=\"type\">Some</span>(parseFunction(result)) <span class=\"keyword\">else</span> <span class=\"type\">None</span></span><br><span class=\"line\">          &#125; <span class=\"keyword\">catch</span> &#123;</span><br><span class=\"line\">            <span class=\"keyword\">case</span> e: <span class=\"type\">Exception</span> =&gt;</span><br><span class=\"line\">              <span class=\"comment\">// 建议在此添加异常日志记录逻辑</span></span><br><span class=\"line\">              logger.info(<span class=\"string\">s&quot;Error processing result: <span class=\"subst\">$&#123;e.getMessage&#125;</span>&quot;</span>)</span><br><span class=\"line\">              <span class=\"type\">None</span></span><br><span class=\"line\">          &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">      &#125;.persist(<span class=\"type\">StorageLevel</span>.<span class=\"type\">MEMORY_ONLY_SER</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">      <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">        <span class=\"comment\">// 将数据写入 Elasticsearch</span></span><br><span class=\"line\">        esRDD.saveToEs(<span class=\"string\">s&quot;<span class=\"subst\">$esIndex</span>/_doc&quot;</span>, <span class=\"type\">Map</span>(<span class=\"string\">&quot;es.mapping.id&quot;</span> -&gt; <span class=\"string\">&quot;key&quot;</span>))</span><br><span class=\"line\">        logger.info(<span class=\"string\">s&quot;Elasticsearch Index <span class=\"subst\">$&#123;esIndex&#125;</span> sync success~~~&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">// 将该索引的统计指标封装成 Map</span></span><br><span class=\"line\">        <span class=\"keyword\">val</span> count = esRDD.count()</span><br><span class=\"line\">        totalCount += count</span><br><span class=\"line\">        <span class=\"keyword\">val</span> metric = <span class=\"type\">Map</span>(<span class=\"string\">&quot;hbaseTable&quot;</span> -&gt; hbaseTable, <span class=\"string\">&quot;count&quot;</span> -&gt; count)</span><br><span class=\"line\"></span><br><span class=\"line\">        metricsList = metric :: metricsList</span><br><span class=\"line\"></span><br><span class=\"line\">      &#125; <span class=\"keyword\">catch</span> &#123;</span><br><span class=\"line\">        <span class=\"keyword\">case</span> e: <span class=\"type\">Exception</span> =&gt; &#123;</span><br><span class=\"line\">          logger.error(<span class=\"string\">&quot;插入es错误!&quot;</span> + e.getMessage)</span><br><span class=\"line\">          e.printStackTrace()</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">      &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">        esRDD.unpersist()</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">val</span> endTime = <span class=\"type\">System</span>.currentTimeMillis()</span><br><span class=\"line\">    <span class=\"keyword\">val</span> btTime = endTime - startTime</span><br><span class=\"line\">    logger.info(<span class=\"string\">&quot;Sync Time:&quot;</span> + btTime + <span class=\"string\">&quot;ms~~~&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 将总体执行时间等信息封装成 Map 对象</span></span><br><span class=\"line\">    <span class=\"keyword\">val</span> jobName = <span class=\"string\">&quot;HBaseToESSync_&quot;</span> + <span class=\"type\">String</span>.valueOf(<span class=\"type\">System</span>.currentTimeMillis());</span><br><span class=\"line\">    <span class=\"keyword\">val</span> sdf = <span class=\"keyword\">new</span> <span class=\"type\">SimpleDateFormat</span>(<span class=\"string\">&quot;yyyy-MM-dd HH:mm:ss&quot;</span>)</span><br><span class=\"line\">    <span class=\"keyword\">val</span> metrics = <span class=\"type\">Map</span>(</span><br><span class=\"line\">      <span class=\"string\">&quot;jobName&quot;</span> -&gt; jobName,</span><br><span class=\"line\">      <span class=\"string\">&quot;totalCount&quot;</span> -&gt; totalCount,</span><br><span class=\"line\">      <span class=\"string\">&quot;jobDetail&quot;</span> -&gt; metricsList,</span><br><span class=\"line\">      <span class=\"string\">&quot;startTime&quot;</span> -&gt; sdf.format(<span class=\"keyword\">new</span> <span class=\"type\">Date</span>(startTime)),</span><br><span class=\"line\">      <span class=\"string\">&quot;endTime&quot;</span> -&gt; sdf.format(<span class=\"keyword\">new</span> <span class=\"type\">Date</span>(endTime)),</span><br><span class=\"line\">      <span class=\"string\">&quot;executionTime_ms&quot;</span> -&gt; btTime,</span><br><span class=\"line\">      <span class=\"string\">&quot;timestamp&quot;</span> -&gt; <span class=\"type\">System</span>.currentTimeMillis()</span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 将指标写入到 ES 中的另一个索引（例如 job_metrics）</span></span><br><span class=\"line\">    spark.sparkContext.parallelize(<span class=\"type\">Seq</span>(metrics))</span><br><span class=\"line\">      .saveToEs(<span class=\"string\">&quot;job_metrics/_doc&quot;</span>, <span class=\"type\">Map</span>(<span class=\"string\">&quot;es.mapping.id&quot;</span> -&gt; <span class=\"string\">&quot;jobName&quot;</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">    spark.stop()</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>打包文件 clean package</li>\n</ul>\n<img src=\"/2025/03/21/%E5%88%A9%E7%94%A8spark%E5%90%8C%E6%AD%A5Hbase%E6%95%B0%E6%8D%AE%E5%88%B0ElasticSearch/image-20250320173103194.png\" class title=\"image-20250320173103194\">\n\n\n\n<h5><span id=\"3编写spark执行脚本\">3.编写spark执行脚本</span></h5><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta prompt_\">#</span><span class=\"language-bash\">!/bin/bash</span></span><br><span class=\"line\">filename=/root/spark-2.4.0-bin/dist/$(date +%Y)/$(date +%m)/$(date +%d)</span><br><span class=\"line\">if [ ! -d &quot;$filename&quot; ]; then</span><br><span class=\"line\">    mkdir -p &quot;$filename&quot;</span><br><span class=\"line\">fi</span><br><span class=\"line\"></span><br><span class=\"line\">/root/spark-2.4.0-bin/bin/spark-submit \\</span><br><span class=\"line\">\t--class com.xxxx.xxxx.HBaseToElasticsearchMultipleTables \\</span><br><span class=\"line\">\t--master local[*] \\</span><br><span class=\"line\">\t--packages org.scala-lang:scala-library:2.11.12,org.apache.hbase:hbase-client:2.5.6,org.apache.hbase:hbase-mapreduce:2.5.6,org.elasticsearch:elasticsearch-spark-20_2.11:7.17.25 \\</span><br><span class=\"line\">\t--conf spark.es.nodes=&quot;xx.xx.xx.xx:9200&quot; \\\t//Elasticsearch 节点的地址</span><br><span class=\"line\">\t--conf spark.es.batch.size.bytes=&quot;10mb&quot; \\\t//控制写入 Elasticsearch 时的批处理大小</span><br><span class=\"line\">\t--conf spark.es.batch.size.entries=&quot;5000&quot; \\\t//控制写入 Elasticsearch 时的批处理大小</span><br><span class=\"line\">\t--conf spark.es.batch.write.refresh=&quot;false&quot; \\\t//设置为 false，以减少写入时的刷新频率，提高性能</span><br><span class=\"line\">\t--conf spark.hbase.zookeeper.quorum=&quot;hbase1&quot; \\\t//配置 HBase 集群信息</span><br><span class=\"line\">\t--conf spark.hbase.zookeeper.property.clientPort=&quot;2181&quot; \\\t//配置 HBase 的 Zookeeper 集群信息</span><br><span class=\"line\">\t--conf spark.serializer=&quot;org.apache.spark.serializer.KryoSerializer&quot; \\\t//指定使用 Kryo 序列化器，以提高序列化性能</span><br><span class=\"line\">\t/root/spark-2.4.0-bin/dist/spark2es_2.11-v1.jar &gt;&gt; $filename/$(date +%Y%m%d)_sync.log 2&gt;&amp;1 &amp;\t//指定包含主类的可执行 JAR 文件,将输出日志重定向到指定文件，并在后台运行该命令</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>class:Jar包执行的主类</li>\n<li>packages:spark执行需要加载的依赖</li>\n<li>conf:spark连接的配置项,在这配置增加了灵活性,也可以在代码中配置</li>\n<li>&#x2F;root&#x2F;spark-2.4.0-bin&#x2F;dist&#x2F;spark2es_2.11-v1.jar:指定jar路劲,输出执行日志</li>\n</ul>\n<h5><span id=\"4服务器设置定时任务crontab\">4.服务器设置定时任务crontab</span></h5><p>执行crontab -e</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">10 07 * * *  /root/spark-2.4.0-bin/dist/run_sync.sh</span><br></pre></td></tr></table></figure>\n\n<h5><span id=\"5同步阿里云hbase数据需要添加认证参数\">5.同步阿里云hbase数据，需要添加认证参数</span></h5><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kinit -kt /path/to/your.keytab your_user@YOUR-REALM.COM</span><br><span class=\"line\"><span class=\"meta prompt_\">#</span><span class=\"language-bash\"><span class=\"comment\">####添加 Kerberos 认证和 HBase 相关配置</span></span></span><br><span class=\"line\">--conf spark.driver.extraJavaOptions=&quot;-Djava.security.krb5.conf=/etc/krb5.conf&quot; \\</span><br><span class=\"line\">--conf spark.executor.extraJavaOptions=&quot;-Djava.security.krb5.conf=/etc/krb5.conf&quot; \\</span><br><span class=\"line\">--conf spark.hadoop.hbase.security.authentication=&quot;kerberos&quot; \\</span><br><span class=\"line\">--conf spark.hadoop.hbase.master.kerberos.principal=&quot;hbase/_HOST@YOUR-REALM.COM&quot; \\</span><br><span class=\"line\">--conf spark.hadoop.hbase.regionserver.kerberos.principal=&quot;hbase/_HOST@YOUR-REALM.COM&quot; \\</span><br></pre></td></tr></table></figure>\n\n<h5><span id=\"6在-spark-submit-中用-files-传递-hbase-sitexml\">6.在 spark-submit 中用 –files 传递 hbase-site.xml</span></h5><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">--files /etc/hbase/conf/hbase-site.xml \\</span><br><span class=\"line\">--conf spark.executor.extraClassPath=./hbase-site.xml \\</span><br><span class=\"line\">--conf spark.driver.extraClassPath=./hbase-site.xml \\</span><br><span class=\"line\"><span class=\"meta prompt_\">#</span><span class=\"language-bash\">并在代码中加载它</span></span><br><span class=\"line\">hBaseConf.addResource(&quot;hbase-site.xml&quot;)</span><br></pre></td></tr></table></figure>\n\n<h5><span id=\"7elasticsearch可以看到有定时任务的索引生成可以看到执行的时间以及同步的数据量大小\">7.ElasticSearch可以看到有定时任务的索引生成,可以看到执行的时间以及同步的数据量大小</span></h5><img src=\"/2025/03/21/%E5%88%A9%E7%94%A8spark%E5%90%8C%E6%AD%A5Hbase%E6%95%B0%E6%8D%AE%E5%88%B0ElasticSearch/image-20250320174118378.png\" class title=\"image-20250320174118378\">\n","more":"<h2 id=\"利用spark同步Hbase数据到ElasticSearch\"><a href=\"#利用spark同步Hbase数据到ElasticSearch\" class=\"headerlink\" title=\"利用spark同步Hbase数据到ElasticSearch\"></a>利用spark同步Hbase数据到ElasticSearch</h2><hr>\n<p><strong>主要实现思路:利用spark-submit 命令 + Scala 代码(亲测:同步10万条数据,38s左右)</strong></p>\n<p>具体实现步骤如下:</p>\n<h5 id=\"1-安装hadoop、habse、zooker、sacla、spark\"><a href=\"#1-安装hadoop、habse、zooker、sacla、spark\" class=\"headerlink\" title=\"1.安装hadoop、habse、zooker、sacla、spark\"></a>1.安装hadoop、habse、zooker、sacla、spark</h5><p>参考此篇博客进行搭建:</p>\n<p>[<a href=\"https://blog.csdn.net/qq_51235856/article/details/125712898]\">https://blog.csdn.net/qq_51235856/article/details/125712898]</a>: </p>\n<h5 id=\"2-编写同步jar包-利用scala语言，编写项目，打包成jar，上传到服务器\"><a href=\"#2-编写同步jar包-利用scala语言，编写项目，打包成jar，上传到服务器\" class=\"headerlink\" title=\"2.编写同步jar包(利用scala语言，编写项目，打包成jar，上传到服务器)\"></a>2.编写同步jar包(利用scala语言，编写项目，打包成jar，上传到服务器)</h5><ul>\n<li><p>Idea中安装Scala插件</p>\n<img src=\"/2025/03/21/%E5%88%A9%E7%94%A8spark%E5%90%8C%E6%AD%A5Hbase%E6%95%B0%E6%8D%AE%E5%88%B0ElasticSearch/image-20250321100343192.png\" class=\"\" title=\"image-20250321100343192\">\n</li>\n<li><p>新建Scala项目</p>\n</li>\n</ul>\n<img src=\"/2025/03/21/%E5%88%A9%E7%94%A8spark%E5%90%8C%E6%AD%A5Hbase%E6%95%B0%E6%8D%AE%E5%88%B0ElasticSearch/image-20250320172304319.png\" class=\"\" title=\"image-20250320172304319\">\n\n<ul>\n<li>在build.sbt中引入依赖,导入的依赖需要考虑兼容性</li>\n</ul>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ThisBuild / version := &quot;v1&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">ThisBuild / scalaVersion := &quot;2.11.12&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">lazy val root = (project in file(&quot;.&quot;))</span><br><span class=\"line\">  .settings(</span><br><span class=\"line\">    name := &quot;spark2es&quot;,</span><br><span class=\"line\">    idePackagePrefix := Some(&quot;com.xxxx.xxxx&quot;)</span><br><span class=\"line\">  )</span><br><span class=\"line\"></span><br><span class=\"line\">libraryDependencies += &quot;org.apache.spark&quot; %% &quot;spark-core&quot; % &quot;2.4.0&quot;</span><br><span class=\"line\">libraryDependencies += &quot;org.elasticsearch&quot; %% &quot;elasticsearch-spark-20&quot; % &quot;7.17.25&quot;</span><br><span class=\"line\">libraryDependencies += &quot;org.apache.hbase&quot; % &quot;hbase-client&quot; % &quot;2.5.6&quot;</span><br><span class=\"line\">libraryDependencies += &quot;org.apache.hbase&quot; % &quot;hbase-server&quot; % &quot;2.5.6&quot;</span><br><span class=\"line\">libraryDependencies += &quot;org.apache.hbase.connectors.spark&quot; % &quot;hbase-spark&quot; % &quot;1.0.0&quot;</span><br><span class=\"line\">libraryDependencies += &quot;org.apache.spark&quot; %% &quot;spark-sql&quot; % &quot;2.4.0&quot;</span><br><span class=\"line\">libraryDependencies += &quot;com.alibaba&quot; % &quot;fastjson&quot; % &quot;1.2.77&quot;</span><br><span class=\"line\">libraryDependencies += &quot;org.apache.hbase&quot; % &quot;hbase-mapreduce&quot; % &quot;2.5.6&quot;</span><br><span class=\"line\">libraryDependencies += &quot;org.scala-lang&quot; % &quot;scala-library&quot; % &quot;2.11.12&quot;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><p>新建scala文件</p>\n<img src=\"/2025/03/21/%E5%88%A9%E7%94%A8spark%E5%90%8C%E6%AD%A5Hbase%E6%95%B0%E6%8D%AE%E5%88%B0ElasticSearch/image-20250320172907896.png\" class=\"\" title=\"image-20250320172907896\">\n</li>\n<li><p>编写文件</p>\n</li>\n</ul>\n<figure class=\"highlight scala\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">object</span> <span class=\"title\">HBaseToElasticsearchMultipleTables</span> </span>&#123;</span><br><span class=\"line\">  <span class=\"keyword\">private</span> <span class=\"keyword\">final</span> <span class=\"keyword\">val</span> logger: <span class=\"type\">Logger</span> = <span class=\"type\">Logger</span>.getLogger(<span class=\"type\">HBaseToElasticsearchMultipleTables</span>.getClass)</span><br><span class=\"line\">  logger.setLevel(<span class=\"type\">Level</span>.<span class=\"type\">DEBUG</span>)</span><br><span class=\"line\">\t</span><br><span class=\"line\">  <span class=\"comment\">//定义Hbase中需要同步的表</span></span><br><span class=\"line\">  <span class=\"keyword\">private</span> <span class=\"keyword\">val</span> parserMapping: <span class=\"type\">Map</span>[<span class=\"type\">String</span>, <span class=\"type\">Result</span> =&gt; <span class=\"type\">Map</span>[<span class=\"type\">String</span>, <span class=\"type\">String</span>]] = <span class=\"type\">Map</span>(</span><br><span class=\"line\">    <span class=\"string\">&quot;student&quot;</span> -&gt; parsestudent,</span><br><span class=\"line\">\t....更多数据</span><br><span class=\"line\">  )</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"comment\">// 定义多个表和对应的索引</span></span><br><span class=\"line\">  <span class=\"keyword\">private</span> <span class=\"keyword\">final</span> <span class=\"keyword\">val</span> tablesAndIndexes = <span class=\"type\">Seq</span>(</span><br><span class=\"line\">    <span class=\"comment\">//student:Hbase表名 student:es索引名 atsn:列簇</span></span><br><span class=\"line\">    (<span class=\"string\">&quot;student&quot;</span>, <span class=\"string\">&quot;student&quot;</span>, <span class=\"string\">&quot;atsn&quot;</span>),</span><br><span class=\"line\">    ....更多数据</span><br><span class=\"line\">  )</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"comment\">//student</span></span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">parsestudent</span></span>(result: <span class=\"type\">Result</span>): <span class=\"type\">Map</span>[<span class=\"type\">String</span>, <span class=\"type\">String</span>] = &#123;</span><br><span class=\"line\">    <span class=\"comment\">//Hbase中的rowkey</span></span><br><span class=\"line\">    <span class=\"keyword\">val</span> rowKey = <span class=\"type\">Bytes</span>.toString(result.getRow)</span><br><span class=\"line\">    <span class=\"keyword\">val</span> userId = <span class=\"type\">Bytes</span>.toString(result.getValue(<span class=\"type\">Bytes</span>.toBytes(<span class=\"string\">&quot;atsn&quot;</span>), <span class=\"type\">Bytes</span>.toBytes(<span class=\"string\">&quot;userId&quot;</span>)))</span><br><span class=\"line\">\t....更多数据</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 构建 Elasticsearch 文档</span></span><br><span class=\"line\">    <span class=\"type\">Map</span>(</span><br><span class=\"line\">      <span class=\"comment\">//key:Es中的字段名 rowKey:Hbase的列名</span></span><br><span class=\"line\">      <span class=\"string\">&quot;key&quot;</span> -&gt; rowKey,</span><br><span class=\"line\">      <span class=\"string\">&quot;userId&quot;</span> -&gt; userId,</span><br><span class=\"line\">\t  ....更多数据</span><br><span class=\"line\">    )</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">main</span></span>(args: <span class=\"type\">Array</span>[<span class=\"type\">String</span>]): <span class=\"type\">Unit</span> = &#123;</span><br><span class=\"line\">    <span class=\"comment\">// 创建 SparkSession</span></span><br><span class=\"line\">    <span class=\"keyword\">val</span> spark = <span class=\"type\">SparkSession</span>.builder()</span><br><span class=\"line\">      .appName(<span class=\"string\">&quot;HBaseToElasticsearch&quot;</span>)</span><br><span class=\"line\">      <span class=\"comment\">//true:连接器将禁用节点发现功能</span></span><br><span class=\"line\">      .config(<span class=\"string\">&quot;spark.es.nodes.wan.only&quot;</span>, <span class=\"string\">&quot;true&quot;</span>)</span><br><span class=\"line\">      <span class=\"comment\">//指定es中id为Hbase中的rowkey,也可以由es自动生成</span></span><br><span class=\"line\">      .config(<span class=\"string\">&quot;spark.es.mapping.id&quot;</span>, <span class=\"string\">&quot;key&quot;</span>)</span><br><span class=\"line\">      <span class=\"comment\">// upsert操作</span></span><br><span class=\"line\">      .config(<span class=\"string\">&quot;spark.es.write.operation&quot;</span>, <span class=\"string\">&quot;upsert&quot;</span>) </span><br><span class=\"line\">      <span class=\"comment\">// 自动创建索引</span></span><br><span class=\"line\">      .config(<span class=\"string\">&quot;spark.es.index.auto.create&quot;</span>, <span class=\"string\">&quot;true&quot;</span>) </span><br><span class=\"line\">      .getOrCreate()</span><br><span class=\"line\">    logger.info(<span class=\"string\">&quot;Elasticsearch init Success~~~&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">val</span> startTime = <span class=\"type\">System</span>.currentTimeMillis()</span><br><span class=\"line\">    <span class=\"comment\">// HBase 配置</span></span><br><span class=\"line\">    <span class=\"keyword\">val</span> hbaseConf = <span class=\"type\">HBaseConfiguration</span>.create()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 统计同步的总条数</span></span><br><span class=\"line\">    <span class=\"keyword\">var</span> totalCount = <span class=\"number\">0</span>L;</span><br><span class=\"line\">    <span class=\"keyword\">var</span> metricsList = <span class=\"type\">List</span>.empty[<span class=\"type\">Map</span>[<span class=\"type\">String</span>, <span class=\"type\">Any</span>]]</span><br><span class=\"line\">    <span class=\"comment\">//循环遍历表和索引</span></span><br><span class=\"line\">    tablesAndIndexes.foreach &#123; <span class=\"keyword\">case</span> (hbaseTable, esIndex, family) =&gt;</span><br><span class=\"line\">      hbaseConf.set(<span class=\"type\">TableInputFormat</span>.<span class=\"type\">INPUT_TABLE</span>, hbaseTable) <span class=\"comment\">// HBase 表名</span></span><br><span class=\"line\"></span><br><span class=\"line\">      <span class=\"comment\">// 定义 Scan</span></span><br><span class=\"line\">      <span class=\"keyword\">val</span> scan = <span class=\"keyword\">new</span> <span class=\"type\">Scan</span>()</span><br><span class=\"line\">      scan.addFamily(<span class=\"type\">Bytes</span>.toBytes(family)) <span class=\"comment\">// 列族名</span></span><br><span class=\"line\"></span><br><span class=\"line\">      <span class=\"keyword\">val</span> scanStr = <span class=\"type\">Base64</span>.getEncoder.encodeToString(<span class=\"type\">ProtobufUtil</span>.toScan(scan).toByteArray)</span><br><span class=\"line\">      hbaseConf.set(<span class=\"type\">TableInputFormat</span>.<span class=\"type\">SCAN</span>, scanStr)</span><br><span class=\"line\"></span><br><span class=\"line\">      <span class=\"comment\">// 读取 HBase 数据</span></span><br><span class=\"line\">      <span class=\"keyword\">val</span> hbaseRDD = spark.sparkContext.newAPIHadoopRDD(</span><br><span class=\"line\">        hbaseConf,</span><br><span class=\"line\">        classOf[<span class=\"type\">TableInputFormat</span>],</span><br><span class=\"line\">        classOf[<span class=\"type\">ImmutableBytesWritable</span>],</span><br><span class=\"line\">        classOf[<span class=\"type\">Result</span>]</span><br><span class=\"line\">      )</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">      <span class=\"comment\">// 处理数据并转换为 Elasticsearch 格式</span></span><br><span class=\"line\">      <span class=\"keyword\">val</span> parseFunction = parserMapping.getOrElse(hbaseTable,</span><br><span class=\"line\">        <span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> <span class=\"type\">IllegalArgumentException</span>(<span class=\"string\">s&quot;未注册的表解析器: <span class=\"subst\">$hbaseTable</span>&quot;</span>))</span><br><span class=\"line\">\t <span class=\"comment\">//增加 Spark 作业的并行度,提高写入性能</span></span><br><span class=\"line\">      <span class=\"keyword\">val</span> targetPartitions = spark.sparkContext.defaultParallelism * <span class=\"number\">4</span></span><br><span class=\"line\">      logger.info(<span class=\"string\">s&quot;hbaseRDD.repartition <span class=\"subst\">$&#123;targetPartitions&#125;</span>&quot;</span>)</span><br><span class=\"line\">\t  </span><br><span class=\"line\">      <span class=\"comment\">//映射Hbase中的列名和Es中的字段名</span></span><br><span class=\"line\">      <span class=\"keyword\">val</span> esRDD = hbaseRDD.repartition(targetPartitions).mapPartitions &#123; partition =&gt;</span><br><span class=\"line\">        partition.flatMap &#123; <span class=\"keyword\">case</span> (_, result) =&gt;</span><br><span class=\"line\">          <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">            <span class=\"keyword\">if</span> (result != <span class=\"literal\">null</span>) <span class=\"type\">Some</span>(parseFunction(result)) <span class=\"keyword\">else</span> <span class=\"type\">None</span></span><br><span class=\"line\">          &#125; <span class=\"keyword\">catch</span> &#123;</span><br><span class=\"line\">            <span class=\"keyword\">case</span> e: <span class=\"type\">Exception</span> =&gt;</span><br><span class=\"line\">              <span class=\"comment\">// 建议在此添加异常日志记录逻辑</span></span><br><span class=\"line\">              logger.info(<span class=\"string\">s&quot;Error processing result: <span class=\"subst\">$&#123;e.getMessage&#125;</span>&quot;</span>)</span><br><span class=\"line\">              <span class=\"type\">None</span></span><br><span class=\"line\">          &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">      &#125;.persist(<span class=\"type\">StorageLevel</span>.<span class=\"type\">MEMORY_ONLY_SER</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">      <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">        <span class=\"comment\">// 将数据写入 Elasticsearch</span></span><br><span class=\"line\">        esRDD.saveToEs(<span class=\"string\">s&quot;<span class=\"subst\">$esIndex</span>/_doc&quot;</span>, <span class=\"type\">Map</span>(<span class=\"string\">&quot;es.mapping.id&quot;</span> -&gt; <span class=\"string\">&quot;key&quot;</span>))</span><br><span class=\"line\">        logger.info(<span class=\"string\">s&quot;Elasticsearch Index <span class=\"subst\">$&#123;esIndex&#125;</span> sync success~~~&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">// 将该索引的统计指标封装成 Map</span></span><br><span class=\"line\">        <span class=\"keyword\">val</span> count = esRDD.count()</span><br><span class=\"line\">        totalCount += count</span><br><span class=\"line\">        <span class=\"keyword\">val</span> metric = <span class=\"type\">Map</span>(<span class=\"string\">&quot;hbaseTable&quot;</span> -&gt; hbaseTable, <span class=\"string\">&quot;count&quot;</span> -&gt; count)</span><br><span class=\"line\"></span><br><span class=\"line\">        metricsList = metric :: metricsList</span><br><span class=\"line\"></span><br><span class=\"line\">      &#125; <span class=\"keyword\">catch</span> &#123;</span><br><span class=\"line\">        <span class=\"keyword\">case</span> e: <span class=\"type\">Exception</span> =&gt; &#123;</span><br><span class=\"line\">          logger.error(<span class=\"string\">&quot;插入es错误!&quot;</span> + e.getMessage)</span><br><span class=\"line\">          e.printStackTrace()</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">      &#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">        esRDD.unpersist()</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">val</span> endTime = <span class=\"type\">System</span>.currentTimeMillis()</span><br><span class=\"line\">    <span class=\"keyword\">val</span> btTime = endTime - startTime</span><br><span class=\"line\">    logger.info(<span class=\"string\">&quot;Sync Time:&quot;</span> + btTime + <span class=\"string\">&quot;ms~~~&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 将总体执行时间等信息封装成 Map 对象</span></span><br><span class=\"line\">    <span class=\"keyword\">val</span> jobName = <span class=\"string\">&quot;HBaseToESSync_&quot;</span> + <span class=\"type\">String</span>.valueOf(<span class=\"type\">System</span>.currentTimeMillis());</span><br><span class=\"line\">    <span class=\"keyword\">val</span> sdf = <span class=\"keyword\">new</span> <span class=\"type\">SimpleDateFormat</span>(<span class=\"string\">&quot;yyyy-MM-dd HH:mm:ss&quot;</span>)</span><br><span class=\"line\">    <span class=\"keyword\">val</span> metrics = <span class=\"type\">Map</span>(</span><br><span class=\"line\">      <span class=\"string\">&quot;jobName&quot;</span> -&gt; jobName,</span><br><span class=\"line\">      <span class=\"string\">&quot;totalCount&quot;</span> -&gt; totalCount,</span><br><span class=\"line\">      <span class=\"string\">&quot;jobDetail&quot;</span> -&gt; metricsList,</span><br><span class=\"line\">      <span class=\"string\">&quot;startTime&quot;</span> -&gt; sdf.format(<span class=\"keyword\">new</span> <span class=\"type\">Date</span>(startTime)),</span><br><span class=\"line\">      <span class=\"string\">&quot;endTime&quot;</span> -&gt; sdf.format(<span class=\"keyword\">new</span> <span class=\"type\">Date</span>(endTime)),</span><br><span class=\"line\">      <span class=\"string\">&quot;executionTime_ms&quot;</span> -&gt; btTime,</span><br><span class=\"line\">      <span class=\"string\">&quot;timestamp&quot;</span> -&gt; <span class=\"type\">System</span>.currentTimeMillis()</span><br><span class=\"line\">    )</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 将指标写入到 ES 中的另一个索引（例如 job_metrics）</span></span><br><span class=\"line\">    spark.sparkContext.parallelize(<span class=\"type\">Seq</span>(metrics))</span><br><span class=\"line\">      .saveToEs(<span class=\"string\">&quot;job_metrics/_doc&quot;</span>, <span class=\"type\">Map</span>(<span class=\"string\">&quot;es.mapping.id&quot;</span> -&gt; <span class=\"string\">&quot;jobName&quot;</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">    spark.stop()</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>打包文件 clean package</li>\n</ul>\n<img src=\"/2025/03/21/%E5%88%A9%E7%94%A8spark%E5%90%8C%E6%AD%A5Hbase%E6%95%B0%E6%8D%AE%E5%88%B0ElasticSearch/image-20250320173103194.png\" class=\"\" title=\"image-20250320173103194\">\n\n\n\n<h5 id=\"3-编写spark执行脚本\"><a href=\"#3-编写spark执行脚本\" class=\"headerlink\" title=\"3.编写spark执行脚本\"></a>3.编写spark执行脚本</h5><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta prompt_\">#</span><span class=\"language-bash\">!/bin/bash</span></span><br><span class=\"line\">filename=/root/spark-2.4.0-bin/dist/$(date +%Y)/$(date +%m)/$(date +%d)</span><br><span class=\"line\">if [ ! -d &quot;$filename&quot; ]; then</span><br><span class=\"line\">    mkdir -p &quot;$filename&quot;</span><br><span class=\"line\">fi</span><br><span class=\"line\"></span><br><span class=\"line\">/root/spark-2.4.0-bin/bin/spark-submit \\</span><br><span class=\"line\">\t--class com.xxxx.xxxx.HBaseToElasticsearchMultipleTables \\</span><br><span class=\"line\">\t--master local[*] \\</span><br><span class=\"line\">\t--packages org.scala-lang:scala-library:2.11.12,org.apache.hbase:hbase-client:2.5.6,org.apache.hbase:hbase-mapreduce:2.5.6,org.elasticsearch:elasticsearch-spark-20_2.11:7.17.25 \\</span><br><span class=\"line\">\t--conf spark.es.nodes=&quot;xx.xx.xx.xx:9200&quot; \\\t//Elasticsearch 节点的地址</span><br><span class=\"line\">\t--conf spark.es.batch.size.bytes=&quot;10mb&quot; \\\t//控制写入 Elasticsearch 时的批处理大小</span><br><span class=\"line\">\t--conf spark.es.batch.size.entries=&quot;5000&quot; \\\t//控制写入 Elasticsearch 时的批处理大小</span><br><span class=\"line\">\t--conf spark.es.batch.write.refresh=&quot;false&quot; \\\t//设置为 false，以减少写入时的刷新频率，提高性能</span><br><span class=\"line\">\t--conf spark.hbase.zookeeper.quorum=&quot;hbase1&quot; \\\t//配置 HBase 集群信息</span><br><span class=\"line\">\t--conf spark.hbase.zookeeper.property.clientPort=&quot;2181&quot; \\\t//配置 HBase 的 Zookeeper 集群信息</span><br><span class=\"line\">\t--conf spark.serializer=&quot;org.apache.spark.serializer.KryoSerializer&quot; \\\t//指定使用 Kryo 序列化器，以提高序列化性能</span><br><span class=\"line\">\t/root/spark-2.4.0-bin/dist/spark2es_2.11-v1.jar &gt;&gt; $filename/$(date +%Y%m%d)_sync.log 2&gt;&amp;1 &amp;\t//指定包含主类的可执行 JAR 文件,将输出日志重定向到指定文件，并在后台运行该命令</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>class:Jar包执行的主类</li>\n<li>packages:spark执行需要加载的依赖</li>\n<li>conf:spark连接的配置项,在这配置增加了灵活性,也可以在代码中配置</li>\n<li>&#x2F;root&#x2F;spark-2.4.0-bin&#x2F;dist&#x2F;spark2es_2.11-v1.jar:指定jar路劲,输出执行日志</li>\n</ul>\n<h5 id=\"4-服务器设置定时任务crontab\"><a href=\"#4-服务器设置定时任务crontab\" class=\"headerlink\" title=\"4.服务器设置定时任务crontab\"></a>4.服务器设置定时任务crontab</h5><p>执行crontab -e</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">10 07 * * *  /root/spark-2.4.0-bin/dist/run_sync.sh</span><br></pre></td></tr></table></figure>\n\n<h5 id=\"5-同步阿里云hbase数据，需要添加认证参数\"><a href=\"#5-同步阿里云hbase数据，需要添加认证参数\" class=\"headerlink\" title=\"5.同步阿里云hbase数据，需要添加认证参数\"></a>5.同步阿里云hbase数据，需要添加认证参数</h5><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kinit -kt /path/to/your.keytab your_user@YOUR-REALM.COM</span><br><span class=\"line\"><span class=\"meta prompt_\">#</span><span class=\"language-bash\"><span class=\"comment\">####添加 Kerberos 认证和 HBase 相关配置</span></span></span><br><span class=\"line\">--conf spark.driver.extraJavaOptions=&quot;-Djava.security.krb5.conf=/etc/krb5.conf&quot; \\</span><br><span class=\"line\">--conf spark.executor.extraJavaOptions=&quot;-Djava.security.krb5.conf=/etc/krb5.conf&quot; \\</span><br><span class=\"line\">--conf spark.hadoop.hbase.security.authentication=&quot;kerberos&quot; \\</span><br><span class=\"line\">--conf spark.hadoop.hbase.master.kerberos.principal=&quot;hbase/_HOST@YOUR-REALM.COM&quot; \\</span><br><span class=\"line\">--conf spark.hadoop.hbase.regionserver.kerberos.principal=&quot;hbase/_HOST@YOUR-REALM.COM&quot; \\</span><br></pre></td></tr></table></figure>\n\n<h5 id=\"6-在-spark-submit-中用-–files-传递-hbase-site-xml\"><a href=\"#6-在-spark-submit-中用-–files-传递-hbase-site-xml\" class=\"headerlink\" title=\"6.在 spark-submit 中用 –files 传递 hbase-site.xml\"></a>6.在 spark-submit 中用 –files 传递 hbase-site.xml</h5><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">--files /etc/hbase/conf/hbase-site.xml \\</span><br><span class=\"line\">--conf spark.executor.extraClassPath=./hbase-site.xml \\</span><br><span class=\"line\">--conf spark.driver.extraClassPath=./hbase-site.xml \\</span><br><span class=\"line\"><span class=\"meta prompt_\">#</span><span class=\"language-bash\">并在代码中加载它</span></span><br><span class=\"line\">hBaseConf.addResource(&quot;hbase-site.xml&quot;)</span><br></pre></td></tr></table></figure>\n\n<h5 id=\"7-ElasticSearch可以看到有定时任务的索引生成-可以看到执行的时间以及同步的数据量大小\"><a href=\"#7-ElasticSearch可以看到有定时任务的索引生成-可以看到执行的时间以及同步的数据量大小\" class=\"headerlink\" title=\"7.ElasticSearch可以看到有定时任务的索引生成,可以看到执行的时间以及同步的数据量大小\"></a>7.ElasticSearch可以看到有定时任务的索引生成,可以看到执行的时间以及同步的数据量大小</h5><img src=\"/2025/03/21/%E5%88%A9%E7%94%A8spark%E5%90%8C%E6%AD%A5Hbase%E6%95%B0%E6%8D%AE%E5%88%B0ElasticSearch/image-20250320174118378.png\" class=\"\" title=\"image-20250320174118378\">\n","categories":[{"name":"技术","path":"api/categories/技术.json"}],"tags":[{"name":"大数据","path":"api/tags/大数据.json"}]}